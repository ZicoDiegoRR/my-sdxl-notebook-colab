{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZicoDiegoRR/stable_diffusion_xl_colab_ui/blob/main/beta_stable_diffusion_xl_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8hug-0Okf8t"
      },
      "source": [
        "###<font color=\"black\"> ¬ª <b><font color=\"red\">Installing Dependencies </b>üíø</font> <font color=\"black\"> ¬´\n",
        "#####„Ö§Run this cell first before creating images!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "GaGpmeILXSGl",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "#@markdown <b>Run this first to install essential libraries!</b><br>\n",
        "#@markdown <small><p>Required to use the generator.\n",
        "from IPython.display import clear_output\n",
        "print(\"‚öôÔ∏è | Downloading libraries...\")\n",
        "!pip install diffusers\n",
        "!pip install torch torchvision torchaudio\n",
        "!pip install -U xformers --index-url https://download.pytorch.org/whl/cu124\n",
        "!pip install transformers\n",
        "!pip install accelerate\n",
        "!pip install opencv-python\n",
        "!pip install peft\n",
        "!pip install --upgrade huggingface_hub\n",
        "!pip install compel\n",
        "!pip install controlnet-aux\n",
        "!export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True\n",
        "clear_output()\n",
        "print(\"üìÅ | All essential libraries have been downloaded.\")\n",
        "print(\"üñå | You can start generating images now.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCBZ305GvH7w"
      },
      "source": [
        "###<font color=\"black\"> ¬ª<b><font color=\"orange\">Running Stable Diffusion</b> üîß</font> <font color=\"black\"> ¬´"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-sdjCI-xvy5",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "from PIL import Image as ImagePIL\n",
        "from compel import Compel, ReturnedEmbeddingsType\n",
        "from controlnet_aux import OpenposeDetector\n",
        "from diffusers import ControlNetModel, StableDiffusionXLPipeline, StableDiffusionXLImg2ImgPipeline, StableDiffusionXLControlNetPipeline, AutoPipelineForInpainting, AutoencoderKL\n",
        "from diffusers import DDPMScheduler, DPMSolverMultistepScheduler, DPMSolverSinglestepScheduler, KDPM2DiscreteScheduler, KDPM2AncestralDiscreteScheduler, EulerDiscreteScheduler, EulerAncestralDiscreteScheduler, HeunDiscreteScheduler, LMSDiscreteScheduler, DEISMultistepScheduler, UniPCMultistepScheduler, DDIMScheduler, PNDMScheduler\n",
        "from diffusers.utils import load_image, make_image_grid\n",
        "from huggingface_hub import login\n",
        "from transformers import pipeline as pipe\n",
        "from transformers import CLIPVisionModelWithProjection\n",
        "from google.colab import drive\n",
        "from IPython.display import display, clear_output\n",
        "from safetensors.torch import load_file\n",
        "from io import BytesIO\n",
        "import ipywidgets as widgets\n",
        "import numpy as np\n",
        "import time\n",
        "import cv2\n",
        "import re\n",
        "import os\n",
        "import subprocess\n",
        "import os.path\n",
        "import torch\n",
        "import random\n",
        "import json\n",
        "import math\n",
        "\n",
        "#@markdown <b>Run the cell to start!</b>\n",
        "\n",
        "#@markdown <small>Just run the cell and enjoy. (required to run the cell above first)</small>\n",
        "\n",
        "#@markdown <small>You can disable Google Drive by not permitting the notebook to access your Google Drive storage.</small>\n",
        "\n",
        "#@markdown <small>If the runtime got restarted, just run it again.</small>\n",
        "\n",
        "# Function to load parameters config\n",
        "def load_param(filename):\n",
        "    try:\n",
        "        with open(filename, 'r') as f:\n",
        "            params = json.load(f)\n",
        "        return params\n",
        "    except FileNotFoundError:\n",
        "        return []\n",
        "\n",
        "# Function to save the data to a json\n",
        "def save_last(filename, data, type):\n",
        "    try:\n",
        "        if os.path.exists(filename):\n",
        "            with open(filename, 'r') as file:\n",
        "                existing_data = json.load(file)\n",
        "        else:\n",
        "            existing_data = {}\n",
        "\n",
        "        if type == \"[Text-to-Image]\":\n",
        "            existing_data['text2img'] = data\n",
        "        elif type == \"[ControlNet]\":\n",
        "            existing_data['controlnet'] = data\n",
        "        elif type == \"[Inpainting]\":\n",
        "            existing_data['inpaint'] = data\n",
        "        with open(filename, 'w') as file:\n",
        "            json.dump(existing_data, file, indent=4)\n",
        "    except Exception as e:\n",
        "        print(f\"Error occurred: {e}\")\n",
        "\n",
        "# Function to load last-generated image\n",
        "def load_last(filename, type):\n",
        "    try:\n",
        "        with open(filename, 'r') as file:\n",
        "            data = json.load(file)\n",
        "            return data.get(type, None)\n",
        "    except (FileNotFoundError, json.JSONDecodeError):\n",
        "        return None\n",
        "\n",
        "# Function to load the saved data from a json\n",
        "def load_number(filename):\n",
        "    try:\n",
        "        with open(filename, 'r') as file:\n",
        "            data = json.load(file)\n",
        "            return data['saved']\n",
        "    except (FileNotFoundError, KeyError):\n",
        "        return None\n",
        "\n",
        "# Function to save the data to a json\n",
        "def save_number(filename, data):\n",
        "    with open(filename, 'w') as file:\n",
        "        json.dump({'saved': data}, file)\n",
        "\n",
        "#Function to save parameters config (had to make separate JSON def to avoid confusion)\n",
        "def save_param(path, data):\n",
        "    with open(path, 'w') as file:\n",
        "        json.dump(data, file)\n",
        "\n",
        "# Function to convert image into depth map\n",
        "def get_depth_map(image, depth_estimator):\n",
        "    image = depth_estimator(image)[\"depth\"]\n",
        "    image = np.array(image)\n",
        "    image = image[:, :, None]\n",
        "    image = np.concatenate([image, image, image], axis=2)\n",
        "    detected_map = torch.from_numpy(image).float() / 255.0\n",
        "    depth_map = detected_map.permute(2, 0, 1)\n",
        "    return depth_map\n",
        "\n",
        "# Only for display in output, nothing crazy\n",
        "def get_depth_map_display(image, depth_estimator):\n",
        "    image = depth_estimator(image)[\"depth\"]\n",
        "    image = np.array(image)\n",
        "    image = image[:, :, None]\n",
        "    image = np.concatenate([image, image, image], axis=2)\n",
        "    return image\n",
        "\n",
        "# Function to restart the runtime to free up some of the VRAM if there's a change in model or the pipeline\n",
        "def restart(new, old):\n",
        "    print(f\"New model is found. Your previous one ({old}) is different than your new one ({new}).\")\n",
        "    print(\"Restarting the runtime is necessary to load the new one.\")\n",
        "    time.sleep(2)\n",
        "    print(\"Restarting the runtime...\")\n",
        "    time.sleep(0.5)\n",
        "    os.kill(os.getpid(), 9)\n",
        "\n",
        "def param_default(): # For parameters validation and/or parameters reset\n",
        "  default_cfg = [\n",
        "      \"\",\n",
        "      \"\",\n",
        "      \"Safe Tensor (.safetensors)\",\n",
        "      \"\",\n",
        "      1024,\n",
        "      1024,\n",
        "      \"Default (defaulting to the model)\",\n",
        "      12,\n",
        "      6,\n",
        "      \"\",\n",
        "      2,\n",
        "      \"\",\n",
        "      \"\",\n",
        "      100,\n",
        "      240,\n",
        "      \"\",\n",
        "      False,\n",
        "      0.7,\n",
        "      \"\",\n",
        "      False,\n",
        "      0.7,\n",
        "      \"\",\n",
        "      False,\n",
        "      0.7,\n",
        "      \"pre-generated text2image image\",\n",
        "      \"\",\n",
        "      False,\n",
        "      0.9,\n",
        "      \"None\",\n",
        "      \"\",\n",
        "      0.7,\n",
        "      False,\n",
        "      False,\n",
        "      False,\n",
        "      False,\n",
        "      False,\n",
        "      \"\",\n",
        "      \"\",\n",
        "      0.3,\n",
        "      \"\",\n",
        "      \"\"\n",
        "  ]\n",
        "  return default_cfg\n",
        "\n",
        "def param_constructor(): # For generating parameters based on the widgets to be saved\n",
        "  param = [\n",
        "        prompt_widget.value,\n",
        "        model_widget.value,\n",
        "        model_format_widget.value,\n",
        "        negative_prompt_widget.value,\n",
        "        width_slider.value,\n",
        "        height_slider.value,\n",
        "        scheduler_dropdown.value,\n",
        "        steps_slider.value,\n",
        "        scale_slider.value,\n",
        "        vae_link_widget.value,\n",
        "        clip_skip_slider.value,\n",
        "        lora_urls_widget.value,\n",
        "        weight_scale_widget.value,\n",
        "        canny_min_slider.value,\n",
        "        canny_max_slider.value,\n",
        "        canny_link_widget.value,\n",
        "        canny_toggle.value,\n",
        "        canny_strength_slider.value,\n",
        "        depth_map_link_widget.value,\n",
        "        depth_map_toggle.value,\n",
        "        depth_strength_slider.value,\n",
        "        openpose_link_widget.value,\n",
        "        openpose_toggle.value,\n",
        "        openpose_strength_slider.value,\n",
        "        inpainting_image_dropdown.value,\n",
        "        mask_image_widget.value,\n",
        "        inpainting_toggle.value,\n",
        "        inpainting_strength_slider.value,\n",
        "        ip_adapter_dropdown.value,\n",
        "        ip_image_link_widget.value,\n",
        "        ip_adapter_strength_slider.value,\n",
        "        freeze_widget.value,\n",
        "        karras_bool.value,\n",
        "        vpred_bool.value,\n",
        "        sgmuniform_bool.value,\n",
        "        res_betas_zero_snr.value,\n",
        "        vae_config.value,\n",
        "        reference_image_link_widget.value,\n",
        "        denoising_strength_slider.value,\n",
        "        ti_urls_widget.value,\n",
        "        ti_tokens_widget.value\n",
        "    ] # 41 values in total\n",
        "  return param\n",
        "\n",
        "def all_widgets(): # Packing all widgets into a single VBox\n",
        "  all_usable_widgets = widgets.VBox([\n",
        "        prompt_widget,\n",
        "        model_widget,\n",
        "        model_format_widget,\n",
        "        negative_prompt_widget,\n",
        "        width_slider,\n",
        "        height_slider,\n",
        "        scheduler_dropdown,\n",
        "        steps_slider,\n",
        "        scale_slider,\n",
        "        vae_link_widget,\n",
        "        clip_skip_slider,\n",
        "        lora_urls_widget,\n",
        "        weight_scale_widget,\n",
        "        canny_min_slider,\n",
        "        canny_max_slider,\n",
        "        canny_link_widget,\n",
        "        canny_toggle,\n",
        "        canny_strength_slider,\n",
        "        depth_map_link_widget,\n",
        "        depth_map_toggle,\n",
        "        depth_strength_slider,\n",
        "        openpose_link_widget,\n",
        "        openpose_toggle,\n",
        "        openpose_strength_slider,\n",
        "        inpainting_image_dropdown,\n",
        "        mask_image_widget,\n",
        "        inpainting_toggle,\n",
        "        inpainting_strength_slider,\n",
        "        ip_adapter_dropdown,\n",
        "        ip_image_link_widget,\n",
        "        ip_adapter_strength_slider,\n",
        "        freeze_widget,\n",
        "        karras_bool,\n",
        "        vpred_bool,\n",
        "        sgmuniform_bool,\n",
        "        res_betas_zero_snr,\n",
        "        vae_config,\n",
        "        reference_image_link_widget,\n",
        "        denoising_strength_slider,\n",
        "        ti_urls_widget,\n",
        "        ti_tokens_widget\n",
        "    ])\n",
        "  return all_usable_widgets\n",
        "\n",
        "# Loading the saved config for the IPyWidgets\n",
        "try:\n",
        "    drive.mount('/content/gdrive', force_remount=True)\n",
        "except Exception as e:\n",
        "    print(\"Excluding Google Drive storage...\")\n",
        "    time.sleep(1.5)\n",
        "\n",
        "if os.path.exists(\"/content/gdrive/MyDrive\"):\n",
        "    base_path = \"/content/gdrive/MyDrive\"\n",
        "    Save_and_Connect_To_GDrive = True\n",
        "else:\n",
        "    base_path = \"/content\"\n",
        "    Save_and_Connect_To_GDrive = False\n",
        "if os.path.exists(f\"{base_path}/parameters.json\"):\n",
        "  cfg = load_param(os.path.join(f\"{base_path}\", \"parameters.json\"))\n",
        "  print(f\"Found a config at {base_path}/parameters.json.\")\n",
        "  if not os.path.exists(f\"{base_path}/Saved Parameters\"):\n",
        "    os.mkdir(f\"{base_path}/Saved Parameters\")\n",
        "  save_param(os.path.join(f\"{base_path}/Saved Parameters/\", \"main_parameters.json\"), cfg)\n",
        "elif not os.path.exists(f\"{base_path}/parameters.json\") or os.path.exists(f\"{base_path}/Saved Parameters/main_parameters.json\"):\n",
        "  cfg = load_param(os.path.join(f\"{base_path}/Saved Parameters/\", \"main_parameters.json\"))\n",
        "  print(f\"Found a config at {base_path}/Saved Parameters/main_parameters.json.\")\n",
        "if cfg:\n",
        "  if len(cfg) < 41:\n",
        "    for i in range(41 - len(cfg)):\n",
        "      cfg.append(None)\n",
        "else:\n",
        "    print(\"No saved config found. Defaulting...\")\n",
        "    time.sleep(1)\n",
        "\n",
        "# Validating the loaded parameters (compatibility feature for using parameters from previous versions)\n",
        "if cfg:\n",
        "  default_cfg = param_default()\n",
        "  for i in range(len(cfg)):\n",
        "    if cfg[i] is None:\n",
        "      cfg[i] = default_cfg[i]\n",
        "  save_param(os.path.join(f\"{base_path}/Saved Parameters/\", \"main_parameters.json\"), cfg)\n",
        "\n",
        "# IPyWidgets‚¨áÔ∏è\n",
        "# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
        "\n",
        "# Image Generation Section\n",
        "prompt_widget = widgets.Textarea(value=cfg[0] if cfg else \"\", placeholder=\"Enter your prompt here\")\n",
        "negative_prompt_widget = widgets.Textarea(value=cfg[3] if cfg else \"\", placeholder=\"What you don't want to see?\")\n",
        "prompts_section = widgets.HBox([widgets.VBox([widgets.Label(value=\"Prompt:\"), prompt_widget]), widgets.VBox([widgets.Label(value=\"Negative prompt:\"), negative_prompt_widget])])\n",
        "\n",
        "prompt_widget.layout.flex = \"1\"\n",
        "negative_prompt_widget.layout.flex = \"1\"\n",
        "\n",
        "model_widget = widgets.Text(value=cfg[1] if cfg else \"\", placeholder=\"HF's repository or direct URL\")\n",
        "model_format_widget = widgets.Dropdown(options=[\"Pickle Tensor (.ckpt)\", \"Safe Tensor (.safetensors)\"], value=cfg[2] if cfg else \"Safe Tensor (.safetensors)\", description=\"Model Format and Link\",)\n",
        "model_input_section = widgets.HBox([model_format_widget, model_widget])\n",
        "\n",
        "def reference_image_upload_handler(change):\n",
        "  if not os.path.exists(\"/content/img2img/\"):\n",
        "    os.mkdir(\"/content/img2img/\")\n",
        "  for file_info in reference_image_upload_widget.value.items():\n",
        "    ref_uploaded_image = file_info[1][\"content\"]\n",
        "    with open(\"/content/img2img/temp.png\", \"wb\") as up:\n",
        "      up.write(ref_uploaded_image)\n",
        "  reference_image_link_widget.value = \"/content/img2img/temp.png\"\n",
        "\n",
        "reference_image_link_widget = widgets.Text(placeholder=\"Img2Img reference link\", description=\"Reference Image\", value=cfg[37] if cfg and (not cfg[37].startswith(\"/content/img2img/\") or os.path.exists(\"/content/img2img/\")) else \"\")\n",
        "reference_image_upload_widget = widgets.FileUpload(accept=\"image/*\", multiple=False)\n",
        "denoising_strength_slider = widgets.FloatSlider(min=0.1, max=1, step=0.01, description=\"Denoising Strength\", value=cfg[38] if cfg else 0.3)\n",
        "reference_image_section = widgets.VBox([widgets.HBox([reference_image_link_widget, reference_image_upload_widget]), widgets.HBox([denoising_strength_slider, widgets.HTML(value=\"Low value means similar to the original image.\")])])\n",
        "reference_image_upload_widget.observe(reference_image_upload_handler, names=\"value\")\n",
        "\n",
        "width_slider = widgets.IntSlider(min=512, max=1536, step=64, value=cfg[4] if cfg else 1024, description=\"Width\")\n",
        "height_slider = widgets.IntSlider(min=512, max=1536, step=64, value=cfg[5] if cfg else 1024, description=\"Height\")\n",
        "image_resolution_section = widgets.HBox([width_slider, height_slider])\n",
        "\n",
        "steps_slider = widgets.IntText(value=cfg[7] if cfg else 12, description=\"Steps\")\n",
        "scale_slider = widgets.FloatSlider(min=1, max=12, step=0.1, value=cfg[8] if cfg else 6, description=\"Scale\")\n",
        "clip_skip_slider = widgets.IntSlider(min=0, max=12, step=1, value=cfg[10] if cfg else 2, description=\"Clip Skip\")\n",
        "generation_parameter_section = widgets.VBox([steps_slider, widgets.HBox([scale_slider, clip_skip_slider])])\n",
        "\n",
        "def scheduler_dropdown_handler(change): # Function to show or hide scheduler booleans\n",
        "  if change[\"new\"] != \"Default (defaulting to the model)\":\n",
        "    scheduler_settings.children = [scheduler_dropdown, karras_bool, vpred_bool, sgmuniform_bool, res_betas_zero_snr, widgets.HTML(value=\"Rescaling the betas to have zero terminal SNR helps to achieve vibrant color, but not necessary.\")]\n",
        "  else:\n",
        "    scheduler_settings.children = [scheduler_dropdown]\n",
        "\n",
        "scheduler_dropdown = widgets.Dropdown(\n",
        "    options=[\n",
        "        \"Default (defaulting to the model)\", \"DPM++ 2M\", \"DPM++ 2M SDE\",\n",
        "        \"DPM++ SDE\", \"DPM2\", \"DDPM\",\n",
        "        \"DPM2 a\", \"DDIM\", \"PNDM\", \"Euler\", \"Euler a\", \"Heun\", \"LMS\",\n",
        "        \"DEIS\", \"UniPC\"\n",
        "    ],\n",
        "    value=cfg[6] if cfg else \"Default (defaulting to the model)\",\n",
        "    description=\"Scheduler\",\n",
        ")\n",
        "karras_bool = widgets.Checkbox(value=cfg[32] if cfg else False, description=\"Enable Karras\")\n",
        "vpred_bool = widgets.Checkbox(value=cfg[33] if cfg else False, description=\"Enable V-prediction\")\n",
        "sgmuniform_bool = widgets.Checkbox(value=cfg[34] if cfg else False, description=\"Enable SGMUniform\")\n",
        "res_betas_zero_snr = widgets.Checkbox(value=cfg[35] if cfg else False, description=\"Rescale beta zero SNR\")\n",
        "scheduler_settings = widgets.VBox([scheduler_dropdown])\n",
        "\n",
        "scheduler_dropdown.observe(scheduler_dropdown_handler, names=\"value\")\n",
        "scheduler_dropdown_handler({\"new\": scheduler_dropdown.value})\n",
        "\n",
        "vae_link_widget = widgets.Text(value=cfg[9] if cfg else \"\", description=\"VAE\", placeholder=\"VAE model link\")\n",
        "vae_config = widgets.Text(value=cfg[36] if cfg else \"\", placeholder=\"VAE config link\")\n",
        "vae_section = widgets.HBox([vae_link_widget, vae_config])\n",
        "\n",
        "token_widget = widgets.Text(description=\"CivitAI Token\", placeholder=\"Avoid 401 error from CivitAI\")\n",
        "freeze_widget = widgets.Checkbox(description=\"Use the same seed\", value=cfg[31] if cfg else False)\n",
        "\n",
        "img2img_settings = widgets.VBox([\n",
        "    prompts_section,\n",
        "    model_input_section,\n",
        "    image_resolution_section,\n",
        "    generation_parameter_section,\n",
        "    reference_image_section,\n",
        "    scheduler_settings,\n",
        "    vae_section,\n",
        "    freeze_widget,\n",
        "    token_widget,\n",
        "    widgets.HTML(value=\"For safety reason, your token <b>won't be saved</b>.\")\n",
        "])\n",
        "\n",
        "text2img_settings = widgets.VBox([\n",
        "    prompts_section,\n",
        "    model_input_section,\n",
        "    image_resolution_section,\n",
        "    generation_parameter_section,\n",
        "    scheduler_settings,\n",
        "    vae_section,\n",
        "    freeze_widget,\n",
        "    token_widget,\n",
        "    widgets.HTML(value=\"For safety reason, your token <b>won't be saved</b>.\")\n",
        "])\n",
        "\n",
        "# LoRA Section\n",
        "def lora_click(link, scale): # Function to add widgets after clicking the plus button\n",
        "  lora_url_input = widgets.Text(value=link, placeholder=\"Input the link here\", description=\"Direct URL\")\n",
        "  lora_scale_input = widgets.FloatSlider(value=scale, min=-5, max=5, step=0.1, description=\"Weight Scale\")\n",
        "  lora_remove_button = widgets.Button(description=\"X\", button_style='danger', layout=widgets.Layout(width='30px', height='30px'))\n",
        "\n",
        "  lora_nested_vbox.children += (lora_url_input, lora_scale_input, lora_remove_button,)\n",
        "  lora_remove_button.on_click(lambda b: lora_remover(list(lora_nested_vbox.children).index(lora_remove_button) - 2, list(lora_nested_vbox.children).index(lora_remove_button) - 1, list(lora_nested_vbox.children).index(lora_remove_button)))\n",
        "  lora_settings.children = [lora_add, lora_nested_vbox]\n",
        "\n",
        "def lora_reader(): # Function to process every value from the widgets into two strings to be fed into the main logic (I'm too lazy to change the main code)\n",
        "  collected_lora_urls = \"\"\n",
        "  collected_lora_scales = \"\"\n",
        "  for i in range(len(lora_nested_vbox.children)):\n",
        "    if i % 3 == 0:\n",
        "      if lora_nested_vbox.children[i].value != \"\":\n",
        "        collected_lora_urls += (lora_nested_vbox.children[i].value + \",\")\n",
        "    elif i % 3 == 1:\n",
        "      if lora_nested_vbox.children[i - 1].value != \"\":\n",
        "        collected_lora_scales += (str(lora_nested_vbox.children[i].value) + \",\")\n",
        "  return collected_lora_urls, collected_lora_scales\n",
        "\n",
        "def lora_remover(link, scale, remove_button): # Function to remove lora (only the widgets, not the actual file)\n",
        "  lora_nested_list = list(lora_nested_vbox.children)\n",
        "  lora_nested_list.pop(remove_button)\n",
        "  lora_nested_list.pop(scale)\n",
        "  lora_nested_list.pop(link)\n",
        "  lora_nested_vbox.children = tuple(lora_nested_list)\n",
        "\n",
        "def lora_reader_upon_starting(): # Function to add widgets based on pre-existing URLs from the saved parameter\n",
        "  lora_links = [word for word in re.split(r\"\\s*,\\s*\", lora_urls_widget.value) if word]\n",
        "  lora_scales = [float(word) for word in re.split(r\"\\s*,\\s*\", weight_scale_widget.value) if word]\n",
        "  for i in range(len(lora_links)):\n",
        "    lora_click(lora_links[i], lora_scales[i])\n",
        "\n",
        "lora_urls_widget = widgets.Text(value=cfg[11] if cfg else \"\")\n",
        "weight_scale_widget = widgets.Text(value=cfg[12] if cfg else \"\")\n",
        "\n",
        "lora_add = widgets.Button(description=\"+\", button_style='success', layout=widgets.Layout(width='30px', height='30px'))\n",
        "lora_nested_vbox = widgets.VBox()\n",
        "lora_settings = widgets.VBox([lora_add])\n",
        "\n",
        "lora_add.on_click(lambda b: lora_click(\"\", 1.0))\n",
        "\n",
        "# Textual Inversion or Embeddings Section\n",
        "def ti_click(link, token):  # Function to add widgets after clicking the plus button\n",
        "    ti_url_input = widgets.Text(value=link, placeholder=\"Input the link here\", description=\"Direct URL\")\n",
        "    ti_tokens_input = widgets.Text(value=token, placeholder=\"Activation tag\", description=\"Token\")\n",
        "    ti_remove_button = widgets.Button(description=\"X\", button_style='danger', layout=widgets.Layout(width='30px', height='30px'))\n",
        "\n",
        "    ti_nested_vbox.children += (ti_url_input, ti_tokens_input, ti_remove_button,)\n",
        "    ti_remove_button.on_click(lambda b: ti_remover(\n",
        "        list(ti_nested_vbox.children).index(ti_remove_button) - 2,\n",
        "        list(ti_nested_vbox.children).index(ti_remove_button) - 1,\n",
        "        list(ti_nested_vbox.children).index(ti_remove_button)\n",
        "    ))\n",
        "    ti_settings.children = [ti_add, ti_nested_vbox]\n",
        "\n",
        "def ti_reader():  # Function to process every value into two strings to be fed into the main logic\n",
        "    collected_ti_urls = \"\"\n",
        "    collected_ti_tokens = \"\"\n",
        "    for i in range(len(ti_nested_vbox.children)):\n",
        "        if i % 3 == 0:\n",
        "          if ti_nested_vbox.children[i].value != \"\":\n",
        "            collected_ti_urls += (ti_nested_vbox.children[i].value + \",\")\n",
        "        elif i % 3 == 1:\n",
        "          if ti_nested_vbox.children[i - 1].value != \"\":\n",
        "            collected_ti_tokens += (ti_nested_vbox.children[i].value + \",\")\n",
        "    return collected_ti_urls, collected_ti_tokens\n",
        "\n",
        "def ti_remover(link, token, remove_button):  # Function to remove textual inversion widgets\n",
        "    ti_nested_list = list(ti_nested_vbox.children)\n",
        "    ti_nested_list.pop(remove_button)\n",
        "    ti_nested_list.pop(token)\n",
        "    ti_nested_list.pop(link)\n",
        "    ti_nested_vbox.children = tuple(ti_nested_list)\n",
        "\n",
        "def ti_reader_upon_starting():  # Function to add widgets from saved parameters\n",
        "    ti_links = [word for word in re.split(r\"\\s*,\\s*\", ti_urls_widget.value)]\n",
        "    if not ti_links[-1]:\n",
        "      ti_links.pop(-1)\n",
        "    ti_tokens = [word for word in re.split(r\"\\s*,\\s*\", ti_tokens_widget.value)]\n",
        "    if not ti_tokens[-1]:\n",
        "      ti_tokens.pop(-1)\n",
        "    if len(ti_tokens) < len(ti_links):\n",
        "      for i in range(len(ti_links) - len(ti_tokens)):\n",
        "        ti_tokens.append(\"\")\n",
        "    for i in range(len(ti_links)):\n",
        "        ti_click(ti_links[i], ti_tokens[i])\n",
        "\n",
        "ti_urls_widget = widgets.Text(value=cfg[39] if cfg else \"\")\n",
        "ti_tokens_widget = widgets.Text(value=cfg[40] if cfg else \"\")\n",
        "\n",
        "ti_add = widgets.Button(description=\"+\", button_style='success', layout=widgets.Layout(width='30px', height='30px'))\n",
        "ti_nested_vbox = widgets.VBox()\n",
        "ti_settings = widgets.VBox([ti_add])\n",
        "ti_tab = widgets.VBox([widgets.HTML(value=\"Due to the architecture, you must pass the activation tag in the Token widget. Leaving it blank will skip the embeddings from being loaded.\"), ti_settings])\n",
        "\n",
        "ti_add.on_click(lambda b: ti_click(\"\", \"\"))\n",
        "\n",
        "# ControlNet Section\n",
        "controlnet_dropdown_choice = [\"Link\", \"Upload\", \"Last Generated Text2Img\", \"Last Generated ControlNet\", \"Last Generated Inpainting\"]\n",
        "def controlnet_dropdown_handler(type, value): # Function to change the image reference based on the selected option in the dropdown\n",
        "  controlnet_url_widgets_list = [canny_link_widget, depth_map_link_widget, openpose_link_widget]\n",
        "  controlnet_upload_widgets_list = [canny_upload, depth_upload, openpose_upload]\n",
        "\n",
        "  controlnet_type = 0 if type == \"canny\" else 1 if type == \"depth\" else 2\n",
        "  controlnet_children = list(canny_settings.children) if controlnet_type == 0 else list(depth_settings.children) if controlnet_type == 1 else list(openpose_settings.children)\n",
        "  if value == \"Link\":\n",
        "    if controlnet_upload_widgets_list[controlnet_type] in controlnet_children:\n",
        "      controlnet_children.pop(2)\n",
        "    controlnet_children.insert(2, controlnet_url_widgets_list[controlnet_type])\n",
        "  elif value == \"Upload\":\n",
        "    if controlnet_url_widgets_list[controlnet_type] in controlnet_children:\n",
        "      controlnet_children.pop(2)\n",
        "    controlnet_children.insert(2, controlnet_upload_widgets_list[controlnet_type])\n",
        "  else:\n",
        "    if controlnet_url_widgets_list[controlnet_type] in controlnet_children:\n",
        "      controlnet_children.pop(2)\n",
        "    for i in range(len(controlnet_url_widgets_list)):\n",
        "      if controlnet_url_widgets_list[i] in controlnet_children:\n",
        "        controlnet_children.remove(controlnet_url_widgets_list[i])\n",
        "      if controlnet_upload_widgets_list[i] in controlnet_children:\n",
        "        controlnet_children.remove(controlnet_upload_widgets_list[i])\n",
        "    if controlnet_type == 0:\n",
        "      canny_link_widget.value = \"\" if value == \"Last Generated Text2Img\" else \"controlnet\" if value == \"Last Generated ControlNet\" else \"inpaint\"\n",
        "    elif controlnet_type == 1:\n",
        "      depth_map_link_widget.value = \"\" if value == \"Last Generated Text2Img\" else \"controlnet\" if value == \"Last Generated ControlNet\" else \"inpaint\"\n",
        "    else:\n",
        "      openpose_link_widget.value = \"\" if value == \"Last Generated Text2Img\" else \"controlnet\" if value == \"Last Generated ControlNet\" else \"inpaint\"\n",
        "\n",
        "  if controlnet_type == 0:\n",
        "    canny_settings.children = tuple(controlnet_children)\n",
        "  elif controlnet_type == 1:\n",
        "    depth_settings.children = tuple(controlnet_children)\n",
        "  else:\n",
        "    openpose_settings.children = tuple(controlnet_children)\n",
        "\n",
        "def canny_popup(change): # Function to display canny settings if true\n",
        "  if change[\"new\"]:\n",
        "    canny_settings.children = [canny_toggle, canny_dropdown, canny_min_slider, canny_max_slider, canny_strength_slider]\n",
        "  else:\n",
        "    canny_settings.children = [canny_toggle]\n",
        "\n",
        "def canny_dropdown_handler(change): # Function to attach the canny dropdown to the controlnet dropdown handler\n",
        "  controlnet_dropdown_handler(\"canny\", change[\"new\"])\n",
        "\n",
        "def canny_upload_handler(change): # Function to load the path of the uploaded image to the image link\n",
        "  if not os.path.exists(\"/content/canny/\"):\n",
        "    os.mkdir(\"/content/canny/\")\n",
        "  for file_info in canny_upload.value.items():\n",
        "    canny_uploaded_image = file_info[1][\"content\"]\n",
        "    with open(\"/content/canny/temp.png\", \"wb\") as up:\n",
        "      up.write(canny_uploaded_image)\n",
        "  canny_link_widget.value = \"/content/canny/temp.png\"\n",
        "\n",
        "canny_upload = widgets.FileUpload(accept=\"image/*\", multiple=False)\n",
        "canny_link_widget = widgets.Text(value=cfg[15] if cfg and (not cfg[15].startswith(\"/content/canny/\") or os.path.exists(\"/content/canny/\")) else \"\", description=\"Canny Link\", placeholder=\"Image link\")\n",
        "\n",
        "canny_dropdown = widgets.Dropdown(options=controlnet_dropdown_choice, value=controlnet_dropdown_choice[2] if canny_link_widget.value == \"\" else controlnet_dropdown_choice[3] if canny_link_widget.value == \"controlnet\" else controlnet_dropdown_choice[4] if canny_link_widget.value == \"inpaint\" else controlnet_dropdown_choice[0], disabled=False, description=\"Reference Image\")\n",
        "canny_min_slider = widgets.IntSlider(min=10, max=500, step=5, value=cfg[13] if cfg else 100, description=\"Min Threshold\")\n",
        "canny_max_slider = widgets.IntSlider(min=100, max=750, step=5, value=cfg[14] if cfg else 240, description=\"Max Threshold\")\n",
        "canny_toggle = widgets.Checkbox(value=cfg[16] if cfg else False, description=\"Enable Canny\")\n",
        "canny_strength_slider = widgets.FloatSlider(min=0.1, max=1, step=0.1, value=cfg[17] if cfg else 0.7, description=\"Canny Strength\")\n",
        "canny_settings = widgets.VBox([canny_toggle])\n",
        "\n",
        "canny_popup({\"new\": canny_toggle.value})\n",
        "canny_upload.observe(canny_upload_handler, names=\"value\")\n",
        "\n",
        "def depthmap_popup(change): # Function to display depth map settings if true\n",
        "  if change[\"new\"]:\n",
        "    depth_settings.children = [depth_map_toggle, depthmap_dropdown, depth_strength_slider]\n",
        "  else:\n",
        "    depth_settings.children = [depth_map_toggle]\n",
        "\n",
        "def depthmap_dropdown_handler(change): # Function to attach the canny dropdown to the controlnet dropdown handler\n",
        "  controlnet_dropdown_handler(\"depth\", change[\"new\"])\n",
        "\n",
        "def depthmap_upload_handler(change): # Function to load the path of the uploaded image to the image link\n",
        "  if not os.path.exists(\"/content/depthmap/\"):\n",
        "    os.mkdir(\"/content/depthmap/\")\n",
        "  for file_info in depth_upload.value.items():\n",
        "    depth_uploaded_image = file_info[1][\"content\"]\n",
        "    with open(\"/content/depthmap/temp.png\", \"wb\") as up:\n",
        "      up.write(depth_uploaded_image)\n",
        "  depth_map_link_widget.value = \"/content/depthmap/temp.png\"\n",
        "\n",
        "depth_upload = widgets.FileUpload(accept=\"image/*\", multiple=False)\n",
        "depth_map_link_widget = widgets.Text(value=cfg[18] if cfg and (not cfg[18].startswith(\"/content/depthmap/\") or os.path.exists(\"/content/depthmap/\")) else \"\", description=\"DepthMap Link\", placeholder=\"Image link\")\n",
        "\n",
        "depthmap_dropdown = widgets.Dropdown(options=controlnet_dropdown_choice, value=controlnet_dropdown_choice[2] if depth_map_link_widget.value == \"\" else controlnet_dropdown_choice[3] if depth_map_link_widget.value == \"controlnet\" else controlnet_dropdown_choice[4] if depth_map_link_widget.value == \"inpaint\" else controlnet_dropdown_choice[0], disabled=False, description=\"Reference Image\")\n",
        "depth_map_toggle = widgets.Checkbox(value=cfg[19] if cfg else False, description=\"Enable Depth Map\")\n",
        "depth_strength_slider = widgets.FloatSlider(min=0.1, max=1, step=0.1, value=cfg[20] if cfg else 0.7, description=\"Depth Strength\")\n",
        "depth_settings = widgets.VBox([depth_map_toggle])\n",
        "\n",
        "depthmap_popup({\"new\": depth_map_toggle.value})\n",
        "depth_upload.observe(depthmap_upload_handler, names=\"value\")\n",
        "\n",
        "def openpose_popup(change):  # Function to display openpose settings if true\n",
        "  if change[\"new\"]:\n",
        "    openpose_settings.children = [openpose_toggle, openpose_dropdown, openpose_strength_slider]\n",
        "  else:\n",
        "    openpose_settings.children = [openpose_toggle]\n",
        "\n",
        "def openpose_dropdown_handler(change): # Function to attach the canny dropdown to the controlnet dropdown handler\n",
        "  controlnet_dropdown_handler(\"openpose\", change[\"new\"])\n",
        "\n",
        "def openpose_upload_handler(change): # Function to load the path of the uploaded image to the image link\n",
        "  print(openpose_upload.value)\n",
        "  if not os.path.exists(\"/content/openpose/\"):\n",
        "    os.mkdir(\"/content/openpose/\")\n",
        "  for file_info in openpose_upload.value.items():\n",
        "    openpose_uploaded_image = file_info[1][\"content\"]\n",
        "    with open(\"/content/openpose/temp.png\", \"wb\") as up:\n",
        "      up.write(openpose_uploaded_image)\n",
        "  openpose_link_widget.value = \"/content/openpose/temp.png\"\n",
        "\n",
        "openpose_upload = widgets.FileUpload(accept=\"image/*\", multiple=False)\n",
        "openpose_link_widget = widgets.Text(value=cfg[21] if cfg and (not cfg[21].startswith(\"/content/openpose/\") or os.path.exists(\"/content/openpose/\")) else \"\", description=\"OpenPose Link\", placeholder=\"Image link\")\n",
        "\n",
        "openpose_dropdown = widgets.Dropdown(options=controlnet_dropdown_choice, value=controlnet_dropdown_choice[2] if openpose_link_widget.value == \"\" else controlnet_dropdown_choice[3] if openpose_link_widget.value == \"controlnet\" else controlnet_dropdown_choice[4] if openpose_link_widget.value == \"inpaint\" else controlnet_dropdown_choice[0], disabled=False, description=\"Reference Image\")\n",
        "openpose_toggle = widgets.Checkbox(value=cfg[22] if cfg else False, description=\"Enable OpenPose\")\n",
        "openpose_strength_slider = widgets.FloatSlider(min=0.1, max=1, step=0.1, value=cfg[23] if cfg else 0.7, description=\"OpenPose Strength\")\n",
        "openpose_settings = widgets.VBox([openpose_toggle])\n",
        "\n",
        "openpose_popup({\"new\": openpose_toggle.value})\n",
        "openpose_upload.observe(openpose_upload_handler, names=\"value\")\n",
        "\n",
        "canny_dropdown_handler({\"new\": canny_dropdown.value})\n",
        "depthmap_dropdown_handler({\"new\": depthmap_dropdown.value})\n",
        "openpose_dropdown_handler({\"new\": openpose_dropdown.value})\n",
        "\n",
        "canny_dropdown.observe(canny_dropdown_handler, names=\"value\")\n",
        "depthmap_dropdown.observe(depthmap_dropdown_handler, names=\"value\")\n",
        "openpose_dropdown.observe(openpose_dropdown_handler, names=\"value\")\n",
        "\n",
        "canny_toggle.observe(canny_popup, names=\"value\")\n",
        "depth_map_toggle.observe(depthmap_popup, names=\"value\")\n",
        "openpose_toggle.observe(openpose_popup, names=\"value\")\n",
        "\n",
        "controlnet_selections = widgets.VBox([widgets.HTML(value=\"<hr>\"), canny_settings, widgets.HTML(value=\"<hr>\"), depth_settings, widgets.HTML(value=\"<hr>\"), openpose_settings, widgets.HTML(value=\"<hr>\")])\n",
        "controlnet_settings = widgets.VBox([\n",
        "    prompts_section,\n",
        "    model_input_section,\n",
        "    image_resolution_section,\n",
        "    generation_parameter_section,\n",
        "    controlnet_selections,\n",
        "    scheduler_settings,\n",
        "    vae_section,\n",
        "    freeze_widget,\n",
        "    token_widget,\n",
        "    widgets.HTML(value=\"For safety reason, your token <b>won't be saved</b>.\")\n",
        "    ])\n",
        "\n",
        "# Inpainting Section\n",
        "inpainting_image_dropdown = widgets.Combobox(\n",
        "    options=[\n",
        "        \"pre-generated text2image image\",\n",
        "        \"pre-generated controlnet image\",\n",
        "        \"previous inpainting image\"\n",
        "    ],\n",
        "    value=cfg[24] if cfg else \"pre-generated text2image image\",\n",
        "    description=\"Inpainting Image\",\n",
        "    ensure_option=False\n",
        ")\n",
        "mask_image_widget = widgets.Text(value=cfg[25] if cfg else \"\", description=\"Mask Image\", placeholder=\"Image link\")\n",
        "inpainting_toggle = widgets.Checkbox(value=cfg[26] if cfg else False, description=\"Enable Inpainting\")\n",
        "inpainting_strength_slider = widgets.FloatSlider(min=0.1, max=1, step=0.1, value=cfg[27] if cfg else 0.9, description=\"Inpainting Strength\")\n",
        "inpainting_settings = widgets.VBox([\n",
        "    inpainting_image_dropdown,\n",
        "    mask_image_widget,\n",
        "    inpainting_toggle,\n",
        "    inpainting_strength_slider,\n",
        "    widgets.HTML(value=\"<b>To be updated in the future.</b>\")\n",
        "])\n",
        "\n",
        "# IP-Adapter Section\n",
        "def ip_remove_button_on_click(path): # Function to remove images from widget and directory\n",
        "  os.remove(path)\n",
        "  ip_grid_button = ip_grid_button_maker(sorted([os.path.join(\"/content/ip_adapter/\", element) for element in os.listdir(\"/content/ip_adapter/\") if os.path.isfile(os.path.join(\"/content/ip_adapter/\", element))]))\n",
        "  ip_settings.children = [ip_adapter_dropdown, ip_image_link_widget, ip_image_upload, ip_adapter_strength_slider, ip_grid_image_html, ip_grid_image, ip_grid_button_html, ip_grid_button]\n",
        "  if not [os.path.join(\"/content/ip_adapter/\", element) for element in os.listdir(\"/content/ip_adapter/\") if os.path.isfile(os.path.join(\"/content/ip_adapter/\", element))]:\n",
        "    ip_adapter_dropdown_popup({\"new\": \"refresh_zero\"})\n",
        "\n",
        "def ip_grid_button_maker(list): # Function to make a grid of images and buttons\n",
        "  list_grid = widgets.GridspecLayout(math.ceil(len(list)/5), 5) if list else widgets.HTML(value=\"No images has been uploaded.\")\n",
        "  buffer = BytesIO()\n",
        "  loaded_image_for_grid = []\n",
        "  if list:\n",
        "    for i in range(math.ceil(len(list)/5)):\n",
        "      for j in range(5):\n",
        "        k = (i*5 + j + 1)\n",
        "        list_grid[i, j] = widgets.Button(description=f\"Remove image {k}\", button_style='danger', layout=widgets.Layout(height='auto', width='auto')) if k <= len(list) else widgets.Button(description=\"\", layout=widgets.Layout(height='auto', width='auto'))\n",
        "        path = list[k - 1] if k <= len(list) else \"\"\n",
        "        list_grid[i, j].on_click(lambda b, path=path: ip_remove_button_on_click(path)) if k <= len(list) else None\n",
        "        loaded_image_for_grid.append(load_image(path)) if k <= len(list) else loaded_image_for_grid.append(load_image(\"https://huggingface.co/IDK-ab0ut/BFIDIW9W29NFJSKAOAOXDOKERJ29W/resolve/main/placeholder.png\"))\n",
        "    ip_image_grid_maker = make_image_grid([element.resize((1024, 1024)) for element in loaded_image_for_grid], rows=math.ceil(len(list)/5), cols=5)\n",
        "    ip_image_grid_maker.save(buffer, format = \"PNG\")\n",
        "    ip_grid_image.value = buffer.getvalue()\n",
        "  else:\n",
        "    ip_settings.children = [ip_adapter_dropdown, ip_image_link_widget, ip_image_upload, ip_adapter_strength_slider]\n",
        "  return list_grid\n",
        "\n",
        "def ip_adapter_dropdown_popup(change): # Function to show or hide the widgets\n",
        "  if change[\"new\"] != \"None\" and change[\"new\"] != \"refresh_zero\":\n",
        "    if not os.path.exists(\"/content/ip_adapter/\"):\n",
        "      os.mkdir(\"/content/ip_adapter/\")\n",
        "    ip_settings.children = [ip_adapter_dropdown, ip_image_link_widget, ip_image_upload, ip_adapter_strength_slider] if not os.listdir(\"/content/ip_adapter/\") else [ip_adapter_dropdown, ip_image_link_widget, ip_image_upload, ip_adapter_strength_slider, ip_grid_image_html, ip_grid_image, ip_grid_button_html, ip_grid_button]\n",
        "  elif change[\"new\"] != \"None\" and change[\"new\"] == \"refresh_zero\":\n",
        "    ip_settings.children = [ip_adapter_dropdown, ip_image_link_widget, ip_image_upload, ip_adapter_strength_slider]\n",
        "  else:\n",
        "    ip_settings.children = [ip_adapter_dropdown]\n",
        "\n",
        "def ip_adapter_upload_handler(change): # Function to trigger the UI logic when images are uploaded\n",
        "  global collected_uploaded_ip_image, ip_grid_button\n",
        "  if not os.path.exists(\"/content/ip_adapter/\"):\n",
        "    os.mkdir(\"/content/ip_adapter/\")\n",
        "  for filename, file_info in ip_image_upload.value.items():\n",
        "    with open(f\"/content/ip_adapter/{filename}\", \"wb\") as up:\n",
        "      up.write(file_info[\"content\"])\n",
        "    collected_uploaded_ip_image += f\"/content/ip_adapter/{filename},\"\n",
        "  ip_grid_button = ip_grid_button_maker(sorted([os.path.join(\"/content/ip_adapter/\", element) for element in os.listdir(\"/content/ip_adapter/\") if os.path.isfile(os.path.join(\"/content/ip_adapter/\", element))]))\n",
        "  ip_settings.children = [ip_adapter_dropdown, ip_image_link_widget, ip_image_upload, ip_adapter_strength_slider, ip_grid_image_html, ip_grid_image, ip_grid_button_html, ip_grid_button]\n",
        "\n",
        "collected_uploaded_ip_image = \"\"\n",
        "initial_ip_image = [word for word in re.split(r\"\\s*,\\s*\", cfg[29]) if word] if cfg else \"\"\n",
        "for i, link in enumerate(initial_ip_image):\n",
        "  if link.startswith(\"/content/ip_adapter/\") and not os.path.exists(\"/content/ip_adapter\"):\n",
        "    initial_ip_image.remove(link)\n",
        "\n",
        "ip_grid_image_html = widgets.HTML(value=\"Uploaded image(s):\")\n",
        "ip_grid_image = widgets.Image()\n",
        "ip_grid_button_html = widgets.HTML(value=\"Remove image(s):\")\n",
        "ip_grid_button = ip_grid_button_maker(sorted([os.path.join(\"/content/ip_adapter/\", element) for element in os.listdir(\"/content/ip_adapter/\") if os.path.isfile(os.path.join(\"/content/ip_adapter/\", element))])) if os.path.exists(\"/content/ip_adapter/\") and os.listdir(\"/content/ip_adapter/\") else widgets.GridspecLayout(1, 5)\n",
        "\n",
        "ip_image_upload = widgets.FileUpload(accept=\"image/*\", multiple=True)\n",
        "ip_image_link_widget = widgets.Text(value=\",\".join(initial_ip_image) if cfg else \"\", description=\"IP Image Link\", placeholder=\"Image links separated by commas\")\n",
        "ip_adapter_strength_slider = widgets.FloatSlider(min=0.1, max=1, step=0.1, value=cfg[30] if cfg else 0.8, description=\"Adapter Strength\")\n",
        "\n",
        "ip_adapter_dropdown = widgets.Dropdown(\n",
        "    options=[\n",
        "        \"ip-adapter-plus_sdxl_vit-h.bin\",\n",
        "        \"ip-adapter-plus-face_sdxl_vit-h.bin\",\n",
        "        \"ip-adapter_sdxl_vit-h.bin\",\n",
        "        \"None\"\n",
        "    ],\n",
        "    value=cfg[28] if cfg else \"None\",\n",
        "    description=\"IP-Adapter\",\n",
        ")\n",
        "ip_settings = widgets.VBox()\n",
        "ip_settings.children = [ip_adapter_dropdown] if ip_adapter_dropdown.value == \"None\" else [ip_adapter_dropdown, ip_image_link_widget, ip_image_upload, ip_adapter_strength_slider] if ip_adapter_dropdown.value != \"None\" and not os.listdir(\"/content/ip_adapter\") else [ip_adapter_dropdown, ip_image_link_widget, ip_image_upload, ip_adapter_strength_slider, ip_grid_image_html, ip_grid_image, ip_grid_button_html, ip_grid_button]\n",
        "\n",
        "ip_image_upload.observe(ip_adapter_upload_handler, names=\"value\")\n",
        "ip_adapter_dropdown.observe(ip_adapter_dropdown_popup, names=\"value\")\n",
        "\n",
        "# Miscellaneous (generate button and freeze feature)\n",
        "def reset_evaluate(result): # Function to set every parameter into the default value\n",
        "  if result == \"yes\":\n",
        "    cfg_reset = param_default()\n",
        "    every_widgets = all_widgets()\n",
        "    for i in range(len(every_widgets.children)):\n",
        "      every_widgets.children[i].value = cfg_reset[i]\n",
        "  reset_display.children = [reset_button]\n",
        "\n",
        "def reset_button_click(): # Function to show a warning when the reset parameter button is clicked\n",
        "  reset_yes_button = widgets.Button(description=\"Yes\", button_style='danger')\n",
        "  reset_no_button = widgets.Button(description=\"No\")\n",
        "\n",
        "  reset_display.children = [widgets.HTML(value=\"Are you sure you want to reset all parameters to default? You still can revert it back after rerunning this cell. LoRA and embeddings won't be reset.\"), widgets.HBox([reset_yes_button, reset_no_button])]\n",
        "  reset_yes_button._click_handlers.callbacks.clear()\n",
        "  reset_no_button._click_handlers.callbacks.clear()\n",
        "\n",
        "  reset_yes_button.on_click(lambda b: reset_evaluate(\"yes\"))\n",
        "  reset_no_button.on_click(lambda b: reset_evaluate(\"no\"))\n",
        "\n",
        "submit_button_widget = widgets.Button(disabled=False, button_style='', description=\"Generate\")\n",
        "dont_spam = widgets.HTML(value=\"Please <b>don't spam</b> the generate button!\")\n",
        "keep_generating = widgets.HTML(value=\"You still can generate even though the cell is complete executing.\")\n",
        "submit_display = widgets.VBox([submit_button_widget, dont_spam, keep_generating], layout=widgets.Layout(width=\"50%\"))\n",
        "reset_button = widgets.Button(description=\"Reset parameters to default\")\n",
        "reset_display = widgets.VBox([reset_button])\n",
        "\n",
        "reset_button.on_click(lambda b: reset_button_click())\n",
        "\n",
        "loaded_model = \"\"\n",
        "loaded_pipeline = \"\"\n",
        "\n",
        "# Miscellaneous (preset system)\n",
        "if not os.path.exists(f\"{base_path}/Saved Parameters/\"):\n",
        "  os.mkdir(f\"{base_path}/Saved Parameters/\")\n",
        "\n",
        "def save_warning_evaluate(result, name):\n",
        "  if result == \"override\":\n",
        "    lora_urls_widget.value, weight_scale_widget.value = lora_reader()\n",
        "    ti_urls_widget.value, ti_tokens_widget.value = ti_reader()\n",
        "    save_params = param_constructor()\n",
        "    save_param(f\"{base_path}/Saved Parameters/{name}.json\", save_params)\n",
        "    load_preset_selection_dropdown.options = list_all_saved_preset()\n",
        "\n",
        "  save_preset_display.children = [save_preset_name_widget, save_preset_button, widgets.HTML(value=\"Clicking the save button will save the current parameters you're using as a new preset for later use.\")] if result != \"override\" else [widgets.HTML(value=f\"Succesfully saved the current parameters as {name}.json in {base_path}/Saved Parameters folder.\"), save_preset_name_widget, save_preset_button, widgets.HTML(value=\"Clicking the save button will save the current parameters you're using as a new preset for later use.\")]\n",
        "  save_preset_button._click_handlers.callbacks.clear()\n",
        "  save_preset_button.on_click(lambda b: save_preset_on_click(save_preset_name_widget.value))\n",
        "\n",
        "def save_warning_if_preset_exists(name):\n",
        "  save_warning_back_button = widgets.Button(description=\"Back\")\n",
        "  save_warning_back_button._click_handlers.callbacks.clear()\n",
        "\n",
        "  save_preset_display.children = [widgets.HTML(value=f\"<span style='color: orange;'>Warning:</span> {name}.json already exists. Saving the current parameters with the same name will override the original saved parameters. Do you wish to continue?\"), save_preset_name_widget, widgets.HBox([save_preset_button, save_warning_back_button])]\n",
        "  save_warning_back_button.on_click(lambda b: save_warning_evaluate(\"back\", name))\n",
        "\n",
        "  save_preset_button._click_handlers.callbacks.clear()\n",
        "  save_preset_button.on_click(lambda b: save_warning_evaluate(\"override\", name))\n",
        "\n",
        "def save_preset_on_click(name):\n",
        "  if name and name not in list_all_saved_preset():\n",
        "    lora_urls_widget.value, weight_scale_widget.value = lora_reader()\n",
        "    ti_urls_widget.value, ti_tokens_widget.value = ti_reader()\n",
        "    save_params = param_constructor()\n",
        "    save_param(f\"{base_path}/Saved Parameters/{name}.json\", save_params)\n",
        "    save_preset_display.children = [widgets.HTML(value=f\"Succesfully saved the current parameters as {name}.json in {base_path}/Saved Parameters folder.\"), save_preset_name_widget, save_preset_button, widgets.HTML(value=\"Clicking the save button will save the current parameters you're using as a new preset for later use.\")]\n",
        "    load_preset_selection_dropdown.options = list_all_saved_preset()\n",
        "  elif name in list_all_saved_preset():\n",
        "    save_warning_if_preset_exists(name)\n",
        "  else:\n",
        "    save_preset_display.children = [widgets.HTML(value=\"<span style='color: red;'>Error:</span> Name cannot be empty!\"), save_preset_name_widget, save_preset_button, widgets.HTML(value=\"Clicking the save button will save the current parameters you're using as a new preset for later use.\")]\n",
        "    time.sleep(1.5)\n",
        "    save_preset_display.children = [save_preset_name_widget, save_preset_button, widgets.HTML(value=\"Clicking the save button will save the current parameters you're using as a new preset for later use.\")]\n",
        "\n",
        "def list_all_saved_preset():\n",
        "  list_of_saved_parameters = [word.replace(\".json\" , \"\") for word in os.listdir(f\"{base_path}/Saved Parameters/\") if os.path.isfile(os.path.join(f\"{base_path}/Saved Parameters/\", word)) and word.endswith(\".json\")]\n",
        "  return list_of_saved_parameters\n",
        "\n",
        "def load_preset_on_click(name):\n",
        "  preset_cfg = load_param(os.path.join(f\"{base_path}/Saved Parameters/\", f\"{name}.json\"))\n",
        "  every_widgets = all_widgets()\n",
        "  for i in range(len(every_widgets.children)):\n",
        "    every_widgets.children[i].value = preset_cfg[i]\n",
        "  lora_reader_upon_starting()\n",
        "  ti_reader_upon_starting()\n",
        "\n",
        "save_preset_button = widgets.Button(description=\"Save current parameters\")\n",
        "save_preset_name_widget = widgets.Text(description=\"Name\", placeholder=\"Preset name\", value=\"\")\n",
        "save_preset_display = widgets.VBox([save_preset_name_widget, save_preset_button, widgets.HTML(value=\"Clicking the save button will save the current parameters you're using as a new preset for later use.\")])\n",
        "\n",
        "load_preset_button = widgets.Button(description=\"Load this preset\")\n",
        "load_preset_selection_dropdown = widgets.Dropdown(description=\"Select your saved preset\")\n",
        "load_preset_selection_dropdown.options = list_all_saved_preset()\n",
        "load_preset_display = widgets.VBox([load_preset_selection_dropdown, load_preset_button, widgets.HTML(value=\"Clicking the load button will override the current parameters.\")])\n",
        "\n",
        "preset_tab = widgets.Tab()\n",
        "preset_tab.layout = widgets.Layout(width=\"99%\")\n",
        "preset_tab.children = [save_preset_display, load_preset_display]\n",
        "preset_tab.set_title(0, \"Save Preset\")\n",
        "preset_tab.set_title(1, \"Load Preset\")\n",
        "\n",
        "save_preset_button.on_click(lambda b: save_preset_on_click(save_preset_name_widget.value))\n",
        "load_preset_button.on_click(lambda b: load_preset_on_click(load_preset_selection_dropdown.value))\n",
        "\n",
        "preset_tab_vbox = widgets.VBox([preset_tab], layout=widgets.Layout(width=\"50%\", align_items=\"flex-end\"))\n",
        "\n",
        "# Miscellaneous (history)\n",
        "def history_quick_reference_controlnet_selector(type, path): # Function to input the image as the reference for ControlNet\n",
        "  global canny_link_widget, canny_toggle, canny_settings, depth_map_link_widget, depth_map_toggle, depth_settings, openpose_link_widget, openpose_toggle, openpose_settings\n",
        "  if type == \"canny\":\n",
        "    canny_link_widget.value = path\n",
        "    canny_dropdown.value = \"Link\"\n",
        "    canny_toggle.value = True\n",
        "    ui.selected_index = 2\n",
        "    canny_settings.children = [canny_toggle, canny_dropdown, canny_link_widget, canny_min_slider, canny_max_slider, canny_strength_slider]\n",
        "  elif type == \"depthmap\":\n",
        "    depth_map_link_widget.value = path\n",
        "    depthmap_dropdown.value = \"Link\"\n",
        "    depth_map_toggle.value = True\n",
        "    ui.selected_index = 2\n",
        "    depth_settings.children = [depth_map_toggle, depthmap_dropdown, depth_map_link_widget, depth_strength_slider]\n",
        "  elif type == \"openpose\":\n",
        "    openpose_link_widget.value = path\n",
        "    openpose_dropdown.value = \"Link\"\n",
        "    openpose_toggle.value = True\n",
        "    ui.selected_index = 2\n",
        "    openpose_settings.children = [openpose_toggle, openpose_dropdown, openpose_link_widget, openpose_strength_slider]\n",
        "  history_button_handler(path)\n",
        "\n",
        "def history_quick_reference_second(type, path): # Function to input the image as the reference image\n",
        "  global ui, ip_adapter_dropdown, reference_image_link_widget, inpainting_image_dropdown, inpainting_toggle\n",
        "  if type == \"img2img\":\n",
        "    reference_image_link_widget.value = path\n",
        "    history_button_handler(path)\n",
        "    ui.selected_index = 1\n",
        "  elif type == \"inpainting\":\n",
        "    inpainting_image_dropdown.value = path\n",
        "    history_button_handler(path)\n",
        "    inpainting_toggle.value = True\n",
        "    ui.selected_index = 3\n",
        "  elif type == \"ip\":\n",
        "    if ip_adapter_dropdown.value == \"None\":\n",
        "      ip_adapter_dropdown.value = \"ip-adapter_sdxl_vit-h.bin\"\n",
        "    if ip_image_link_widget.value == \"\":\n",
        "      ip_image_link_widget.value = path\n",
        "    else:\n",
        "      ip_image_link_widget.value += \",\" + path\n",
        "    history_button_handler(path)\n",
        "    ui.selected_index = 6\n",
        "  elif type == \"controlnet\":\n",
        "    history_back_button_second = widgets.Button(description=\"Back\", button_style='danger')\n",
        "    history_image_display_first.children = [widgets.HTML(value=\"Image will show up here. (from the newest to the oldest)\"), history_image_widget, history_image_modification_date, widgets.HBox([history_quick_reference_canny, history_quick_reference_depthmap, history_quick_reference_openpose]), history_back_button_second]\n",
        "\n",
        "    history_back_button_second._click_handlers.callbacks.clear()\n",
        "    history_quick_reference_canny._click_handlers.callbacks.clear()\n",
        "    history_quick_reference_depthmap._click_handlers.callbacks.clear()\n",
        "    history_quick_reference_openpose._click_handlers.callbacks.clear()\n",
        "\n",
        "    history_quick_reference_canny.on_click(lambda b: history_quick_reference_controlnet_selector(\"canny\", path))\n",
        "    history_quick_reference_depthmap.on_click(lambda b: history_quick_reference_controlnet_selector(\"depthmap\", path))\n",
        "    history_quick_reference_openpose.on_click(lambda b: history_quick_reference_controlnet_selector(\"openpose\", path))\n",
        "    history_back_button_second.on_click(lambda b: history_quick_reference_first(path))\n",
        "\n",
        "def history_quick_reference_first(path): # Function to use an image from history to be the reference image of Img2Img, ControlNet, or Inpainting\n",
        "  history_back_button_first = widgets.Button(description=\"Back\", button_style='danger')\n",
        "  history_image_display_first.children = [widgets.HTML(value=\"Image will show up here. (from the newest to the oldest)\"), history_image_widget, history_image_modification_date, widgets.HBox([history_quick_reference_img2img, history_quick_reference_controlnet, history_quick_reference_inpainting, history_quick_reference_ip_adapter]), history_back_button_first]\n",
        "\n",
        "  history_back_button_first._click_handlers.callbacks.clear()\n",
        "  history_quick_reference_img2img._click_handlers.callbacks.clear()\n",
        "  history_quick_reference_controlnet._click_handlers.callbacks.clear()\n",
        "  history_quick_reference_inpainting._click_handlers.callbacks.clear()\n",
        "  history_quick_reference_ip_adapter._click_handlers.callbacks.clear()\n",
        "\n",
        "  history_back_button_first.on_click(lambda b: history_button_handler(path))\n",
        "  history_quick_reference_img2img.on_click(lambda b: history_quick_reference_second(\"img2img\", path))\n",
        "  history_quick_reference_controlnet.on_click(lambda b: history_quick_reference_second(\"controlnet\", path))\n",
        "  history_quick_reference_inpainting.on_click(lambda b: history_quick_reference_second(\"inpainting\", path))\n",
        "  history_quick_reference_ip_adapter.on_click(lambda b: history_quick_reference_second(\"ip\", path))\n",
        "\n",
        "def history_button_handler(path): # Function to show and replace image from history upon clicking a button\n",
        "  history_image_widget.value = open(path, \"rb\").read()\n",
        "  history_image_modification_date.value = f\"Last modification time: {time.strftime('%B, %d %Y %H:%M:%S', time.localtime(os.path.getmtime(path)))}\"\n",
        "  history_image_display_first.children = [widgets.HTML(value=\"Image will show up here. (from the newest to the oldest)\"), history_image_widget, history_image_modification_date, history_quick_reference_button]\n",
        "\n",
        "  history_quick_reference_button._click_handlers.callbacks.clear()\n",
        "  history_quick_reference_button.on_click(lambda b: history_quick_reference_first(path))\n",
        "\n",
        "def grid(list): # Function to make a grid of buttons\n",
        "  list_grid = widgets.GridspecLayout(math.ceil(len(list)/10), 10) if list else widgets.HTML(value=\"Nothing in here currently.\")\n",
        "  if list:\n",
        "    for i in range(math.ceil(len(list)/10)):\n",
        "      for j in range(10):\n",
        "        k = (i*10 + j + 1)\n",
        "        list_grid[i, j] = widgets.Button(description=str(k), layout=widgets.Layout(height='auto', width='auto')) if k <= len(list) else widgets.Button(description=\"\", layout=widgets.Layout(height='auto', width='auto'))\n",
        "        path = list[k - 1] if k <= len(list) else \"\"\n",
        "        list_grid[i, j].on_click(lambda b, path=path: history_button_handler(path)) if k <= len(list) else None\n",
        "  return list_grid\n",
        "\n",
        "def history_display(): # Main logic for history\n",
        "  text2img_listdir = sorted([os.path.join(f\"{base_path}/Text2Img\", element) for element in os.listdir(f\"{base_path}/Text2Img\") if element.endswith(\".png\") and os.path.isfile(os.path.join(f\"{base_path}/Text2Img\", element))], key=os.path.getmtime, reverse=True) if os.path.exists(f\"{base_path}/Text2Img\") else []\n",
        "  controlnet_listdir = sorted([os.path.join(f\"{base_path}/ControlNet\", element) for element in os.listdir(f\"{base_path}/ControlNet\") if element.endswith(\".png\") and os.path.isfile(os.path.join(f\"{base_path}/ControlNet\", element))], key=os.path.getmtime, reverse=True) if os.path.exists(f\"{base_path}/ControlNet\") else []\n",
        "  inpainting_listdir = sorted([os.path.join(f\"{base_path}/Inpainting\", element) for element in os.listdir(f\"{base_path}/Inpainting\") if element.endswith(\".png\") and os.path.isfile(os.path.join(f\"{base_path}/Inpainting\", element))], key=os.path.getmtime, reverse=True) if os.path.exists(f\"{base_path}/Inpainting\") else []\n",
        "  img2img_listdir = sorted([os.path.join(f\"{base_path}/Img2Img\", element) for element in os.listdir(f\"{base_path}/Img2Img\") if element.endswith(\".png\") and os.path.isfile(os.path.join(f\"{base_path}/Img2Img\", element))], key=os.path.getmtime, reverse=True) if os.path.exists(f\"{base_path}/Img2Img\") else []\n",
        "\n",
        "  text2img_list = grid(text2img_listdir)\n",
        "  controlnet_list = grid(controlnet_listdir)\n",
        "  inpainting_list = grid(inpainting_listdir)\n",
        "  img2img_list = grid(img2img_listdir)\n",
        "\n",
        "  history_accordion = widgets.Accordion(continuous_update = True)\n",
        "  history_image_modification_date = widgets.HTML()\n",
        "  history_image_widget = widgets.Image()\n",
        "\n",
        "  history_image_display_first = widgets.VBox([widgets.HTML(value=\"Image will show up here. (from the newest to the oldest)\"), history_image_widget, history_image_modification_date])\n",
        "  history_accordion.children = [text2img_list, img2img_list, controlnet_list, inpainting_list]\n",
        "\n",
        "  history_accordion.set_title(0, \"Text-to-Image History\")\n",
        "  history_accordion.set_title(1, \"Image-to-Image History\")\n",
        "  history_accordion.set_title(2, \"ControlNet History\")\n",
        "  history_accordion.set_title(3, \"Inpainting History\")\n",
        "  history_display_vbox = widgets.VBox([history_accordion, history_image_display_first])\n",
        "  return text2img_list, controlnet_list, inpainting_list, img2img_list\n",
        "\n",
        "history_quick_reference_button = widgets.Button(description=\"Use as a reference\")\n",
        "history_quick_reference_img2img = widgets.Button(description=\"Image-to-image\")\n",
        "history_quick_reference_controlnet = widgets.Button(description=\"ControlNet\")\n",
        "history_quick_reference_inpainting = widgets.Button(description=\"Inpainting\")\n",
        "history_quick_reference_ip_adapter = widgets.Button(description=\"IP-Adapter\")\n",
        "\n",
        "history_quick_reference_canny = widgets.Button(description=\"Canny\")\n",
        "history_quick_reference_depthmap = widgets.Button(description=\"DepthMap\")\n",
        "history_quick_reference_openpose = widgets.Button(description=\"OpenPose\")\n",
        "\n",
        "history_accordion = widgets.Accordion(continuous_update = True)\n",
        "history_image_modification_date = widgets.HTML()\n",
        "history_image_widget = widgets.Image()\n",
        "\n",
        "history_image_display_first = widgets.VBox([widgets.HTML(value=\"Image will show up here. (from the newest to the oldest)\"), history_image_widget, history_image_modification_date], continuous_update = True)\n",
        "text2img_list, controlnet_list, inpainting_list, img2img_list = history_display()\n",
        "history_accordion.children = [text2img_list, controlnet_list, inpainting_list, img2img_list]\n",
        "\n",
        "history_accordion.set_title(0, \"Text-to-Image History üîÆ‚úç\")\n",
        "history_accordion.set_title(1, \"Image-to-Image History üîÆüé®\")\n",
        "history_accordion.set_title(2, \"ControlNet History üîÆüîß\")\n",
        "history_accordion.set_title(3, \"Inpainting History üîÆüñåÔ∏è\")\n",
        "\n",
        "history_display_vbox = widgets.VBox([history_accordion, history_image_display_first], continuous_update = True)\n",
        "\n",
        "# Accordion, Tab, and  UI display grouping\n",
        "def checking_the_selected_tab_index(change):\n",
        "  global tab_selected_index\n",
        "  tab_selected_index = change[\"new\"]\n",
        "  if tab_selected_index > 3:\n",
        "    submit_display.layout.visibility = \"hidden\"\n",
        "  else:\n",
        "    submit_display.layout.visibility = \"visible\"\n",
        "\n",
        "ui = widgets.Tab()\n",
        "ui.children = [widgets.VBox([text2img_settings, reset_display]), widgets.VBox([img2img_settings, reset_display]), widgets.VBox([controlnet_settings, reset_display]), widgets.VBox([inpainting_settings, reset_display]), lora_settings, ti_tab, ip_settings, history_display_vbox]\n",
        "ui_titles = [\"Text-to-image ‚úç\", \"Image-to-image üé®\", \"ControlNet üñºÔ∏èüîß\", \"Inpainting üñºÔ∏èüñåÔ∏è\", \"LoRA Settings üìÅüñåÔ∏è\", \"Textual Inversion üìÉüñåÔ∏è\", \"IP-Adapter Settings üñºÔ∏èüìù\", \"History üîÆüìú\"]\n",
        "for i, title in enumerate(ui_titles):\n",
        "  ui.set_title(i, title)\n",
        "\n",
        "ui.observe(checking_the_selected_tab_index, names=\"selected_index\")\n",
        "checking_the_selected_tab_index({\"name\": \"selected_index\", \"new\": ui.selected_index, \"old\": None, \"type\": \"change\", \"owner\": ui})\n",
        "# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
        "\n",
        "# The IPyWidgets handler\n",
        "\n",
        "def widget(): # Function to display the ui and update the history\n",
        "    text2img_list, controlnet_list, inpainting_list, img2img_list = history_display()\n",
        "    history_accordion.children = [text2img_list, controlnet_list, inpainting_list, img2img_list]\n",
        "    history_display_vbox.children = [history_accordion, history_image_display_first]\n",
        "\n",
        "    clear_output()\n",
        "    submit_display.layout.visibility = \"visible\"\n",
        "    lora_add.layout.display = \"inline-block\"\n",
        "    ti_add.layout.display = \"inline-block\"\n",
        "    display(ui, widgets.HBox([submit_display, preset_tab_vbox]))\n",
        "\n",
        "def submit(_): # Function to trigger the main logic\n",
        "    submit_display.layout.visibility = \"hidden\"\n",
        "    lora_add.layout.display = \"none\"\n",
        "    ti_add.layout.display = \"none\"\n",
        "    lora_urls_widget.value, weight_scale_widget.value = lora_reader()\n",
        "    ti_urls_widget.value, ti_tokens_widget.value = ti_reader()\n",
        "    ip_image_link_widget.value += \",\" + \",\".join([word for word in re.split(r\"\\s*,\\s*\", collected_uploaded_ip_image) if word not in ip_image_link_widget.value])\n",
        "    submit_button()\n",
        "\n",
        "# Main logic\n",
        "def submit_button():\n",
        "    torch.backends.cudnn.benchmark=True\n",
        "    os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:16\"\n",
        "    os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "    Freeze = freeze_widget.value\n",
        "\n",
        "    # Handling Google Drive and seed\n",
        "    filename = os.path.join(base_path, \"random_number.json\")\n",
        "    saved_number = load_number(filename)\n",
        "    if not Freeze:\n",
        "        # Generate a new random number if Freeze is False\n",
        "        random_number = random.randint(1, 1000000000000)\n",
        "        save_number(filename, random_number)\n",
        "        saved_number = load_number(filename)\n",
        "    else:\n",
        "        # Use the saved number if Freeze is True\n",
        "        if saved_number is not None:\n",
        "            saved_number = saved_number\n",
        "        else:\n",
        "            print(\"No saved seed found. Generating new one...\")\n",
        "            random_number = random.randint(1, 1000000000000)\n",
        "            save_number(filename, random_number)\n",
        "            saved_number = load_number(filename)\n",
        "\n",
        "    # Handling user's input‚¨áÔ∏è\n",
        "    # ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
        "    Prompt = prompt_widget.value\n",
        "    Model = model_widget.value\n",
        "    Model_Format = model_format_widget.value\n",
        "    Negative_Prompt = negative_prompt_widget.value\n",
        "\n",
        "    Width = width_slider.value\n",
        "    Height = height_slider.value\n",
        "    Steps = steps_slider.value\n",
        "    Scale = scale_slider.value\n",
        "    VAE_Link = vae_link_widget.value\n",
        "    VAE_Config = vae_config.value\n",
        "    Clip_Skip = clip_skip_slider.value\n",
        "\n",
        "    Reference_Image = reference_image_link_widget.value\n",
        "    Denoising_Strength = denoising_strength_slider.value\n",
        "\n",
        "    Scheduler = scheduler_dropdown.value\n",
        "    Karras = karras_bool.value\n",
        "    V_Prediction = vpred_bool.value\n",
        "    SGMUniform = sgmuniform_bool.value\n",
        "    Rescale_betas_to_zero_SNR = res_betas_zero_snr.value\n",
        "\n",
        "    LoRA_URLs = lora_urls_widget.value\n",
        "    Weight_Scale = weight_scale_widget.value\n",
        "    Token = token_widget.value\n",
        "\n",
        "    Textual_Inversion_URLs = ti_urls_widget.value\n",
        "    Textual_Inversion_Tokens = ti_tokens_widget.value\n",
        "\n",
        "    minimum_canny_threshold = canny_min_slider.value\n",
        "    maximum_canny_threshold = canny_max_slider.value\n",
        "    Canny_Link = canny_link_widget.value\n",
        "    Canny = canny_toggle.value\n",
        "    Canny_Strength = canny_strength_slider.value\n",
        "\n",
        "    DepthMap_Link = depth_map_link_widget.value\n",
        "    Depth_Map = depth_map_toggle.value\n",
        "    Depth_Strength = depth_strength_slider.value\n",
        "\n",
        "    OpenPose_Link = openpose_link_widget.value\n",
        "    Open_Pose = openpose_toggle.value\n",
        "    Open_Pose_Strength = openpose_strength_slider.value\n",
        "\n",
        "    Inpainting_Image = inpainting_image_dropdown.value\n",
        "    Mask_Image = mask_image_widget.value\n",
        "    Inpainting = inpainting_toggle.value\n",
        "    Inpainting_Strength = inpainting_strength_slider.value\n",
        "\n",
        "    IP_Adapter = ip_adapter_dropdown.value\n",
        "    IP_Image_Link = ip_image_link_widget.value\n",
        "    IP_Adapter_Strength = ip_adapter_strength_slider.value\n",
        "    # ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
        "\n",
        "    # Selecting image\n",
        "    last_generation_loading = os.path.join(base_path, \"last_generation.json\")\n",
        "    global pipeline_type, tab_selected_index\n",
        "    selected_tab_for_pipeline = tab_selected_index\n",
        "\n",
        "    if Canny and selected_tab_for_pipeline == 2:\n",
        "        if Canny_Link == \"inpaint\":\n",
        "            Canny_link = load_last(last_generation_loading, 'inpaint')\n",
        "        elif Canny_Link == \"controlnet\":\n",
        "            Canny_link = load_last(last_generation_loading, 'controlnet')\n",
        "        elif not Canny_Link:\n",
        "            Canny_link = load_last(last_generation_loading, 'text2img')\n",
        "        else:\n",
        "            Canny_link = Canny_Link\n",
        "        if Canny_link or os.path.exists(Canny_link):\n",
        "            pipeline_type = \"controlnet\"\n",
        "    else:\n",
        "        Canny_link = \"\"\n",
        "\n",
        "    if Depth_Map and selected_tab_for_pipeline == 2:\n",
        "        if DepthMap_Link == \"inpaint\":\n",
        "            Depthmap_Link = load_last(last_generation_loading, 'inpaint')\n",
        "        elif DepthMap_Link == \"controlnet\":\n",
        "            Depthmap_Link = load_last(last_generation_loading, 'controlnet')\n",
        "        elif not DepthMap_Link:\n",
        "            Depthmap_Link = load_last(last_generation_loading, 'text2img')\n",
        "        else:\n",
        "            Depthmap_Link = DepthMap_Link\n",
        "        if Depthmap_Link or os.path.exists(Depthmap_Link):\n",
        "            pipeline_type = \"controlnet\"\n",
        "    else:\n",
        "        Depthmap_Link = \"\"\n",
        "\n",
        "    if Open_Pose and selected_tab_for_pipeline == 2:\n",
        "        if OpenPose_Link == \"inpaint\":\n",
        "            Openpose_Link = load_last(last_generation_loading, 'inpaint')\n",
        "        elif OpenPose_Link == \"controlnet\":\n",
        "            Openpose_Link = load_last(last_generation_loading, 'controlnet')\n",
        "        elif not OpenPose_Link:\n",
        "            Openpose_Link = load_last(last_generation_loading, 'text2img')\n",
        "        else:\n",
        "            Openpose_Link = OpenPose_Link\n",
        "        if Openpose_Link or os.path.exists(Openpose_Link):\n",
        "            pipeline_type = \"controlnet\"\n",
        "    else:\n",
        "        Openpose_Link = \"\"\n",
        "\n",
        "    active_inpaint = False\n",
        "    if Inpainting and selected_tab_for_pipeline == 3:\n",
        "        if Canny or Depth_Map or Open_Pose:\n",
        "            raise TypeError(\"You checked both ControlNet and Inpainting, which will cause incompatibility issues during your run. As of now, there's no alternative way to merge StableDiffusionXLControlNetPipeline and StableDiffusionXLInpaintingPipeline without causing any issues. Perhaps you want to use only one of them?\")\n",
        "        if not Mask_Image:\n",
        "            raise ValueError(\"You checked Inpainting while you're leaving Mask_Image empty. Mask_Image is required for Inpainting!\")\n",
        "        if Inpainting_Image == \"pre-generated text2image image\":\n",
        "            inpaint_img = load_last(last_generation_loading, 'text2img')\n",
        "        elif Inpainting_Image == \"pre-generated controlnet image\":\n",
        "            inpaint_img = load_last(last_generation_loading, 'controlnet')\n",
        "        elif Inpainting_Image == \"previous inpainting image\":\n",
        "            inpaint_img = load_last(last_generation_loading, 'inpaint')\n",
        "        else:\n",
        "            inpaint_image = Inpainting_Image\n",
        "        if inpaint_img is not None and os.path.exists(inpaint_img):\n",
        "            pipeline_type = \"inpaint\"\n",
        "            inpaint_image = load_image(inpaint_img).resize((1024, 1024))\n",
        "            mask_image = load_image(Mask_Image).resize((1024, 1024))\n",
        "            active_inpaint = True\n",
        "            display(make_image_grid([inpaint_image, mask_image], rows=1, cols=2))\n",
        "\n",
        "    if Reference_Image and selected_tab_for_pipeline == 1:\n",
        "      ref_image = load_image(Reference_Image)\n",
        "      if ref_image or os.path.exists(ref_image):\n",
        "        pipeline_type = \"img2img\"\n",
        "    else:\n",
        "      ref_image = \"\"\n",
        "\n",
        "    if not IP_Image_Link and IP_Adapter != \"None\":\n",
        "        raise ValueError(f\"You selected {IP_Adapter}, but left the IP_Image_Link empty. Please change the IP_Adapter to None or add at least one image in IP_Image_Link!\")\n",
        "    if selected_tab_for_pipeline == 0 or (not Canny_link and not Depthmap_Link and not Openpose_Link and not active_inpaint and not ref_image):\n",
        "        pipeline_type = \"text2img\"\n",
        "\n",
        "    # Saving parameters config 1st phase\n",
        "    params = param_constructor()\n",
        "    save_param(f\"{base_path}/Saved Parameters/main_parameters.json\", params)\n",
        "    if os.path.exists(os.path.join(f\"{base_path}\", \"parameters.json\")):\n",
        "      os.remove(os.path.join(f\"{base_path}\", \"parameters.json\"))\n",
        "\n",
        "    # Checking if previous loaded model or pipeline is the same as the new one\n",
        "    global loaded_model, loaded_pipeline\n",
        "    if loaded_model and loaded_model != model_widget.value:\n",
        "        restart(model_widget.value, loaded_model)\n",
        "    if loaded_pipeline and loaded_pipeline != pipeline_type:\n",
        "        restart(pipeline_type, loaded_pipeline)\n",
        "\n",
        "    # Logic to handle ControlNet and/or MultiControlNets\n",
        "    if Canny and Canny_link is not None:\n",
        "        if \"canny\" not in loaded_controlnet_model:\n",
        "          global canny_model\n",
        "          canny_model = ControlNetModel.from_pretrained(\"diffusers/controlnet-canny-sdxl-1.0\", torch_dtype=torch.float16, use_safetensors=True, low_cpu_mem_usage=True)\n",
        "          loaded_controlnet_model[0] = \"canny\"\n",
        "          controlnets[0] = canny_model\n",
        "        print(\"üèûÔ∏è | Converting image with Canny Edge Detection...\")\n",
        "        c_img = load_image(Canny_link)\n",
        "        image_canny = np.array(c_img)\n",
        "        image_canny = cv2.Canny(image_canny, minimum_canny_threshold, maximum_canny_threshold)\n",
        "        image_canny = image_canny[:, :, None]\n",
        "        image_canny = np.concatenate([image_canny, image_canny, image_canny], axis=2)\n",
        "        canny_image = ImagePIL.fromarray(image_canny)\n",
        "        print(\"‚úÖ | Canny Edge Detection is complete.\")\n",
        "        time.sleep(1)\n",
        "        display(make_image_grid([c_img, canny_image.resize((1024, 1024))], rows=1, cols=2))\n",
        "        images[0] = canny_image.resize((1024, 1024))\n",
        "        controlnets_scale[0] = Canny_Strength\n",
        "\n",
        "    if Depth_Map and Depthmap_Link is not None:\n",
        "        if \"depth\" not in loaded_controlnet_model:\n",
        "          global depthmap_model\n",
        "          loaded_controlnet_model[1] = \"depth\"\n",
        "          depthmap_model = ControlNetModel.from_pretrained(\"diffusers/controlnet-depth-sdxl-1.0\", torch_dtype=torch.float16, use_safetensors=True, low_cpu_mem_usage=True).to(\"cuda\")\n",
        "          controlnets[1] = depthmap_model\n",
        "        print(\"üèûÔ∏è | Converting image with Depth Map...\")\n",
        "        image_depth = load_image(Depthmap_Link).resize((1024, 1024))\n",
        "        depth_estimator = pipe(\"depth-estimation\")\n",
        "        depth_map = get_depth_map(image_depth, depth_estimator).unsqueeze(0).half().to(\"cpu\")\n",
        "        images[1] = depth_map\n",
        "        depth_map_display = ImagePIL.fromarray(get_depth_map_display(image_depth, depth_estimator))\n",
        "        print(\"‚úÖ | Depth Map is complete.\")\n",
        "        controlnets_scale[1] = Depth_Strength\n",
        "        time.sleep(1)\n",
        "        display(make_image_grid([image_depth, depth_map_display], rows=1, cols=2))\n",
        "\n",
        "    if Open_Pose and Openpose_Link is not None:\n",
        "        if \"openpose\" not in loaded_controlnet_model:\n",
        "          global openpose, openpose_model\n",
        "          loaded_controlnet_model[2] = \"openpose\"\n",
        "          openpose = OpenposeDetector.from_pretrained(\"lllyasviel/ControlNet\").to(\"cpu\")\n",
        "          openpose_model = ControlNetModel.from_pretrained(\"thibaud/controlnet-openpose-sdxl-1.0\", torch_dtype=torch.float16, low_cpu_mem_usage=True).to(\"cuda\")\n",
        "          controlnets[2] = openpose_model\n",
        "        print(\"üèûÔ∏è | Converting image with Open Pose...\")\n",
        "        image_openpose = load_image(Openpose_Link)\n",
        "        openpose_image = openpose(image_openpose)\n",
        "        images[2] = openpose_image.resize((1024, 1024))\n",
        "        print(\"‚úÖ | Open Pose is done.\")\n",
        "        controlnets_scale[2] = Open_Pose_Strength\n",
        "        display(make_image_grid([image_openpose, openpose_image.resize((1024, 1024))], rows=1, cols=2))\n",
        "\n",
        "    # Logic to handle VAE\n",
        "    if VAE_Link and VAE_Config:\n",
        "        if not os.path.exists(\"/content/VAE\"):\n",
        "            os.mkdir(\"VAE\")\n",
        "        vae_filename = VAE_Link.replace(\"/\", \"_\").replace(\".\", \"_\") + \".safetensors\"\n",
        "        if VAE_Link.startswith(\"http\"):\n",
        "            if \"civitai.com\" in VAE_Link:\n",
        "                if \"?\" in VAE_Link or \"&\" in VAE_Link:\n",
        "                    vae_link = VAE_Link + \"&token=\" + Token\n",
        "                else:\n",
        "                    vae_link = VAE_Link + \"token=\" + Token\n",
        "            else:\n",
        "                vae_link = VAE_Link\n",
        "            if not os.path.exists(f\"/content/VAE/{vae_filename}\"):\n",
        "                !cd /content/VAE; wget -O \"$vae_filename\" \"$vae_link\"\n",
        "                !cd /content/VAE; wget -O config.json \"$VAE_Config\"\n",
        "        vae_path = f\"/content/VAE/{vae_filename}\" if VAE_Link.startswith(\"http\") else VAE_Link\n",
        "        vae = AutoencoderKL.from_single_file(vae_path, config=\"/content/VAE/config.json\", torch_dtype=torch.float16, local_files_only=True)\n",
        "    elif VAE_Link and not VAE_Config:\n",
        "        vae = None\n",
        "        print(\"You inputted a VAE link, but not the config. Config is essential to load the model.\")\n",
        "        print(\"Skipping VAE...\")\n",
        "\n",
        "    # Logic to differentiate if the model is Hugging Face's repository\n",
        "    global pipeline\n",
        "    if Model.count(\"/\") == 1 and (not Model.startswith(\"https://\") or not Model.startswith(\"http://\")):\n",
        "        if all(cn is None for cn in controlnets) and pipeline_type != \"img2img\" and not active_inpaint and (pipeline_type != \"text2img\" or not loaded_pipeline) and (not loaded_model or model_widget.value != loaded_model):\n",
        "            if VAE_Link:\n",
        "                pipeline = StableDiffusionXLPipeline.from_pretrained(Model, vae=vae, torch_dtype=torch.float16).to(\"cuda\")\n",
        "            else:\n",
        "                pipeline = StableDiffusionXLPipeline.from_pretrained(Model, torch_dtype=torch.float16).to(\"cuda\")\n",
        "        elif active_inpaint and pipeline_type != \"img2img\" and all(cn is None for cn in controlnets) and (pipeline_type != \"inpaint\" or not loaded_pipeline) and (not loaded_model or model_widget.value != loaded_model):\n",
        "            if VAE_Link:\n",
        "                pipeline = AutoPipelineForInpainting.from_pretrained(Model, vae=vae, torch_dtype=torch.float16).to(\"cuda\")\n",
        "            else:\n",
        "                pipeline = AutoPipelineForInpainting.from_pretrained(Model, torch_dtype=torch.float16).to(\"cuda\")\n",
        "        elif pipeline_type != \"img2img\" and (pipeline_type != \"controlnet\" or not loaded_pipeline) and (not loaded_model or model_widget.value != loaded_model):\n",
        "            if VAE_Link:\n",
        "                pipeline = StableDiffusionXLControlNetPipeline.from_pretrained(Model, controlnet=[element for element in controlnets if element], vae=vae, torch_dtype=torch.float16).to(\"cuda\")\n",
        "            else:\n",
        "                pipeline = StableDiffusionXLControlNetPipeline.from_pretrained(Model, controlnet=[element for element in controlnets if element], torch_dtype=torch.float16).to(\"cuda\")\n",
        "        elif pipeline_type == \"img2img\" and (pipeline_type != \"img2img\" or not loaded_pipeline) and (not loaded_model or model_widget.value != loaded_model):\n",
        "            if VAE_Link:\n",
        "                pipeline = StableDiffusionXLImg2ImgPipeline.from_pretrained(Model, vae=vae, torch_dtype=torch.float16).to(\"cuda\")\n",
        "            else:\n",
        "                pipeline = StableDiffusionXLImg2ImgPipeline.from_pretrained(Model, torch_dtype=torch.float16).to(\"cuda\")\n",
        "    else:\n",
        "        if not os.path.exists(\"/content/Checkpoint\"):\n",
        "            os.mkdir(\"Checkpoint\")\n",
        "        if \".ckpt\" in Model_Format:\n",
        "            format = \".ckpt\"\n",
        "        elif \".safetensors\" in Model_Format:\n",
        "            format = \".safetensors\"\n",
        "        checkpoint_name = f\"checkpoint_model{format}\"\n",
        "        if Token and \"civitai.com\" in Model:\n",
        "            if \"?\" in Model or \"&\" in Model:\n",
        "                checkpoint_link = f\"{Model}&token={Token}\"\n",
        "            else:\n",
        "                checkpoint_link = f\"{Model}token={Token}\"\n",
        "        else:\n",
        "            checkpoint_link = Model\n",
        "        Model_folder = Model.replace(\"/\", \"_\").replace(\".\", \"_\")\n",
        "        Model_path = f\"/content/Checkpoint/{Model_folder}/{checkpoint_name}\"\n",
        "        Model_path_folder = f\"/content/Checkpoint/{Model_folder}\"\n",
        "        if not os.path.exists(Model_path):\n",
        "            if not os.path.exists(Model_path_folder):\n",
        "                os.mkdir(Model_path_folder)\n",
        "            !cd \"$Model_path_folder\"; wget -O \"$checkpoint_name\" \"$checkpoint_link\"\n",
        "        try:\n",
        "            if all(cn is None for cn in controlnets) and pipeline_type != \"img2img\" and not active_inpaint and (pipeline_type != \"text2img\" or not loaded_pipeline) and (not loaded_model or model_widget.value != loaded_model):\n",
        "                if VAE_Link:\n",
        "                    pipeline = StableDiffusionXLPipeline.from_single_file(Model_path, vae=vae, torch_dtype=torch.float16, variant=\"fp16\").to(\"cuda\")\n",
        "                else:\n",
        "                    pipeline = StableDiffusionXLPipeline.from_single_file(Model_path, torch_dtype=torch.float16, variant=\"fp16\").to(\"cuda\")\n",
        "            elif pipeline_type != \"img2img\" and active_inpaint and all(cn is None for cn in controlnets) and (pipeline_type != \"inpaint\" or not loaded_pipeline) and (not loaded_model or model_widget.value != loaded_model):\n",
        "                if VAE_Link:\n",
        "                    pipeline = AutoPipelineForInpainting.from_single_file(Model_path, vae=vae, torch_dtype=torch.float16, variant=\"fp16\").to(\"cuda\")\n",
        "                else:\n",
        "                    pipeline = AutoPipelineForInpainting.from_single_file(Model_path, torch_dtype=torch.float16, variant=\"fp16\").to(\"cuda\")\n",
        "            elif pipeline_type != \"img2img\" and (pipeline_type != \"controlnet\" or not loaded_pipeline) and (not loaded_model or model_widget.value != loaded_model):\n",
        "                if VAE_Link:\n",
        "                    pipeline = StableDiffusionXLControlNetPipeline.from_single_file(Model_path, controlnet=[element for element in controlnets if element], vae=vae, torch_dtype=torch.float16, variant=\"fp16\").to(\"cuda\")\n",
        "                else:\n",
        "                    pipeline = StableDiffusionXLControlNetPipeline.from_single_file(Model_path, controlnet=[element for element in controlnets if element], torch_dtype=torch.float16, variant=\"fp16\").to(\"cuda\")\n",
        "            elif pipeline_type == \"img2img\" and (pipeline_type != \"img2img\" or not loaded_pipeline) and (not loaded_model or model_widget.value != loaded_model):\n",
        "                if VAE_Link:\n",
        "                    pipeline = StableDiffusionXLImg2ImgPipeline.from_single_file(Model_path, vae=vae, torch_dtype=torch.float16, variant=\"fp16\").to(\"cuda\")\n",
        "                else:\n",
        "                    pipeline = StableDiffusionXLImg2ImgPipeline.from_single_file(Model_path, torch_dtype=torch.float16, variant=\"fp16\").to(\"cuda\")\n",
        "        except (ValueError, OSError):\n",
        "            pass\n",
        "            os.remove(Model_path)\n",
        "            if not Token and \"civitai.com\" in Model:\n",
        "                Warning = \"You inputted a CivitAI's link, but your token is empty. It's possible that you got unauthorized access during the download.\"\n",
        "            else:\n",
        "                Warning = \"Did you input the correct link? Or did you use the correct format?\"\n",
        "            raise TypeError(f\"The link ({Model}) contains unsupported file or the download was corrupted. {Warning}\")\n",
        "\n",
        "    if IP_Adapter != \"None\":\n",
        "        pipeline.image_encoder = CLIPVisionModelWithProjection.from_pretrained(\n",
        "            \"h94/IP-Adapter\",\n",
        "            subfolder=\"models/image_encoder\",\n",
        "            torch_dtype=torch.float16,\n",
        "        ).to(\"cuda\")\n",
        "\n",
        "    if not loaded_model:\n",
        "        loaded_model = model_widget.value\n",
        "    if not loaded_pipeline:\n",
        "        loaded_pipeline = pipeline_type\n",
        "\n",
        "    # Seed, safety checker, and memory attention (Xformers)\n",
        "    pipeline.enable_xformers_memory_efficient_attention()\n",
        "    generator = torch.Generator(\"cpu\").manual_seed(saved_number)\n",
        "    pipeline.safety_checker = None\n",
        "\n",
        "    # Handling schedulers\n",
        "    Prediction_type = \"v_prediction\" if V_Prediction else \"epsilon\"\n",
        "    scheduler_args = {\"prediction_type\": Prediction_type,\n",
        "                           \"use_karras_sigmas\": Karras,\n",
        "                           \"rescale_betas_zero_snr\": Rescale_betas_to_zero_SNR\n",
        "                           }\n",
        "    if SGMUniform:\n",
        "      scheduler_args[\"timestep_spacing\"] = \"trailing\"\n",
        "    Scheduler_used = [\"\", f\"{Scheduler} \", \"\", \"\", \"\"]\n",
        "    Scheduler_used[0] = \"V-Prediction \" if Prediction_type == \"v_prediction\" else \"\"\n",
        "    Scheduler_used[2] = \"Karras \" if Karras else \"\"\n",
        "    Scheduler_used[3] = \"SGMUniform \" if SGMUniform else \"\"\n",
        "    Scheduler_used[4] = \"with zero SNR betas rescaling\" if Rescale_betas_to_zero_SNR else \"\"\n",
        "    if Scheduler == \"DPM++ 2M\":\n",
        "        pipeline.scheduler = DPMSolverMultistepScheduler.from_config(pipeline.scheduler.config, **scheduler_args)\n",
        "    elif Scheduler == \"DPM++ 2M SDE\":\n",
        "        pipeline.scheduler = DPMSolverMultistepScheduler.from_config(pipeline.scheduler.config, algorithm_type=\"sde-dpmsolver++\", **scheduler_args)\n",
        "    elif Scheduler == \"DPM++ SDE\":\n",
        "        pipeline.scheduler = DPMSolverSinglestepScheduler.from_config(pipeline.scheduler.config, **scheduler_args)\n",
        "    elif Scheduler == \"DPM2\":\n",
        "        pipeline.scheduler = KDPM2DiscreteScheduler.from_config(pipeline.scheduler.config, **scheduler_args)\n",
        "    elif Scheduler == \"DPM2 a\":\n",
        "        pipeline.scheduler = KDPM2AncestralDiscreteScheduler.from_config(pipeline.scheduler.config, **scheduler_args)\n",
        "    elif Scheduler == \"DDPM\":\n",
        "        pipeline.scheduler = DDPMScheduler.from_config(pipeline.scheduler.config, **scheduler_args)\n",
        "    elif Scheduler == \"Euler\":\n",
        "        pipeline.scheduler = EulerDiscreteScheduler.from_config(pipeline.scheduler.config, **scheduler_args)\n",
        "    elif Scheduler == \"Euler a\":\n",
        "        pipeline.scheduler = EulerAncestralDiscreteScheduler.from_config(pipeline.scheduler.config, **scheduler_args)\n",
        "    elif Scheduler == \"Heun\":\n",
        "        pipeline.scheduler = HeunDiscreteScheduler.from_config(pipeline.scheduler.config, **scheduler_args)\n",
        "    elif Scheduler == \"LMS\":\n",
        "        pipeline.scheduler = LMSDiscreteScheduler.from_config(pipeline.scheduler.config, **scheduler_args)\n",
        "    elif Scheduler == \"DEIS\":\n",
        "        pipeline.scheduler = DEISMultistepScheduler.from_config(pipeline.scheduler.config, **scheduler_args)\n",
        "    elif Scheduler == \"UniPC\":\n",
        "        pipeline.scheduler = UniPCMultistepScheduler.from_config(pipeline.scheduler.config, **scheduler_args)\n",
        "    elif Scheduler == \"DDIM\":\n",
        "        pipeline.scheduler = DDIMScheduler.from_config(pipeline.scheduler.config, **scheduler_args)\n",
        "    elif Scheduler == \"PNDM\":\n",
        "        pipeline.scheduler = PNDMScheduler.from_config(pipeline.scheduler.config, **scheduler_args)\n",
        "\n",
        "    # Prompt weighting using Compel\n",
        "    compel = Compel(tokenizer=[pipeline.tokenizer, pipeline.tokenizer_2], text_encoder=[pipeline.text_encoder, pipeline.text_encoder_2], returned_embeddings_type=ReturnedEmbeddingsType.PENULTIMATE_HIDDEN_STATES_NON_NORMALIZED, requires_pooled=[False, True], truncate_long_prompts=False)\n",
        "    conditioning, pooled = compel([Prompt, Negative_Prompt])\n",
        "\n",
        "    # Logic to load LoRA(s)\n",
        "    if LoRA_URLs:\n",
        "        # Preprocessing the urls and weight before downloading\n",
        "        lora_list = []\n",
        "        lora_path = []\n",
        "        unique_lora_urls = []\n",
        "        lora_links = [word for word in re.split(r\"\\s*,\\s*\", LoRA_URLs) if word]\n",
        "        if not os.path.exists(\"/content/LoRAs\"):\n",
        "            os.mkdir(\"LoRAs\")\n",
        "        if not Weight_Scale:\n",
        "            scales_string = [\"1\"] * len(lora_links)\n",
        "        elif Weight_Scale and len(re.split(r\",| ,\", Weight_Scale)) < len(lora_links):\n",
        "            scales_string = re.split(r\",| ,\", Weight_Scale)\n",
        "            for j in range(len(lora_links) - len(scales_string)):\n",
        "                scales_string.append(\"1\")\n",
        "        else:\n",
        "            scales_string = re.split(r\"\\s*,\\s*\", Weight_Scale)\n",
        "        scales = [float(num) for num in scales_string if num]\n",
        "\n",
        "        # Downloading the files and removing any duplicates\n",
        "        for i, link in enumerate(lora_links, start=1):\n",
        "          if link not in unique_lora_urls:\n",
        "            unique_lora_urls.append(link)\n",
        "            path_file = os.path.join(\"/content/LoRAs\", link.replace(\"/\", \"_\").replace(\".\", \"_\"))\n",
        "            if not os.path.exists(path_file) and \"http\" in link:\n",
        "                os.makedirs(path_file)\n",
        "            lora_name = link.replace(\"/\", \"_\").replace(\".\", \"_\")\n",
        "            lora_file_name = f\"lora_{lora_name}.safetensors\"\n",
        "            if \"civitai.com\" in link and Token:\n",
        "                if \"&\" in link or \"?\" in link:\n",
        "                    civit_link = f\"{link}&token={Token}\"\n",
        "                else:\n",
        "                    civit_link = f\"{link}?token={Token}\"\n",
        "                if not os.path.isfile(os.path.join(path_file, lora_file_name)):\n",
        "                    !cd \"$path_file\"; wget -O \"$lora_file_name\" \"$civit_link\"\n",
        "                lora_list.append(lora_file_name)\n",
        "                lora_path.append(path_file)\n",
        "            elif not link.startswith(\"/content\"):\n",
        "                if not os.path.isfile(os.path.join(path_file, lora_file_name)):\n",
        "                    !cd \"$path_file\"; wget -O \"$lora_file_name\" \"$link\"\n",
        "                lora_list.append(lora_file_name)\n",
        "                lora_path.append(path_file)\n",
        "            else:\n",
        "                if link.startswith(\"/content/gdrive/MyDrive\"):\n",
        "                    constructed_gdrive_link = link\n",
        "                else:\n",
        "                    constructed_gdrive_link = f\"/content/gdrive/MyDrive/{link}\"\n",
        "                link_from_gdrive = constructed_gdrive_link.split(\"/\")\n",
        "                lora_path.append(\"/\".join([word for word in link_from_gdrive if \".safetensors\" not in word]))\n",
        "                lora_list.append(link_from_gdrive[-1])\n",
        "\n",
        "        # Loading the downloaded weights into the model\n",
        "        lora_weights = [word for word in lora_list if word.endswith(\".safetensors\")]\n",
        "        lora_names = [word.replace(\".safetensors\", \"\") for word in lora_weights]\n",
        "        for p in range(len(lora_weights)):\n",
        "            try:\n",
        "                pipeline.load_lora_weights(f\"{lora_path[p]}/{lora_weights[p]}\", adapter_name=lora_names[p])\n",
        "            except Exception as e:\n",
        "                print(f\"Skipping {lora_weights[p]}. Reason: {e}\")\n",
        "        pipeline.set_adapters(lora_names, adapter_weights=scales)\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    # Logic to handle the embeddings or textual inversion\n",
        "    if Textual_Inversion_URLs:\n",
        "        # Preprocessing the urls and weight before downloading\n",
        "        ti_list = []\n",
        "        ti_path = []\n",
        "        unique_ti_urls = []\n",
        "        ti_links = [word for word in re.split(r\"\\s*,\\s*\", Textual_Inversion_URLs)]\n",
        "        ti_tokens = [word for word in re.split(r\"\\s*\\s*\", Textual_Inversion_Tokens)]\n",
        "        if not os.path.exists(\"/content/Embeddings\"):\n",
        "            os.mkdir(\"/content/Embeddings\")\n",
        "\n",
        "        # Downloading the files and removing any duplicates\n",
        "        for i, link in enumerate(ti_links, start=1):\n",
        "          if link not in unique_ti_urls and link:\n",
        "            unique_ti_urls.append(link)\n",
        "            ti_path_file = os.path.join(\"/content/LoRAs\", link.replace(\"/\", \"_\").replace(\".\", \"_\"))\n",
        "            if not os.path.exists(ti_path_file) and \"http\" in link:\n",
        "                os.makedirs(ti_path_file)\n",
        "            ti_name = link.replace(\"/\", \"_\").replace(\".\", \"_\")\n",
        "            ti_file_name = f\"embeddings_{ti_name}.safetensors\"\n",
        "            if \"civitai.com\" in link and Token:\n",
        "                if \"&\" in link or \"?\" in link:\n",
        "                    ti_civit_link = f\"{link}&token={Token}\"\n",
        "                else:\n",
        "                    ti_civit_link = f\"{link}?token={Token}\"\n",
        "                if not os.path.isfile(os.path.join(ti_path_file, ti_file_name)):\n",
        "                    !cd \"$ti_path_file\"; wget -O \"$ti_file_name\" \"$ti_civit_link\"\n",
        "                ti_list.append(ti_file_name)\n",
        "                ti_path.append(ti_path_file)\n",
        "            elif not link.startswith(\"/content\"):\n",
        "                if not os.path.isfile(os.path.join(ti_path_file, ti_file_name)):\n",
        "                    !cd \"$ti_path_file\"; wget -O \"$ti_file_name\" \"$link\"\n",
        "                ti_list.append(ti_file_name)\n",
        "                ti_path.append(ti_path_file)\n",
        "            else:\n",
        "                if link.startswith(\"/content/gdrive/MyDrive\"):\n",
        "                    ti_constructed_gdrive_link = link\n",
        "                else:\n",
        "                    ti_constructed_gdrive_link = f\"/content/gdrive/MyDrive/{link}\"\n",
        "                ti_link_from_gdrive = ti_constructed_gdrive_link.split(\"/\")\n",
        "                ti_path.append(\"/\".join([word for word in ti_link_from_gdrive if \".safetensors\" not in word]))\n",
        "                ti_list.append(ti_link_from_gdrive[-1])\n",
        "          else:\n",
        "            ti_tokens.pop(i)\n",
        "\n",
        "        # Loading the downloaded weights into the model\n",
        "        for p in range(len(ti_list)):\n",
        "            try:\n",
        "                ti_dict = load_file(f\"{ti_path[p]}/{ti_list[p]}\")\n",
        "                pipeline.load_textual_inversion(ti_dict[\"clip_g\"], token=ti_tokens[p], text_encoder=pipeline.text_encoder_2, tokenizer=pipeline.tokenizer_2)\n",
        "                pipeline.load_textual_inversion(ti_dict[\"clip_l\"], token=ti_tokens[p], text_encoder=pipeline.text_encoder, tokenizer=pipeline.tokenizer)\n",
        "            except Exception as e:\n",
        "                print(f\"Skipping {ti_list[p]}. Reason: {e}\")\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    # Logic to handle image(s) for IP-Adapter + display\n",
        "    if IP_Adapter != \"None\":\n",
        "        # Loading the images\n",
        "        adapter_image = []\n",
        "        simple_Url = [word for word in re.split(r\"\\s*,\\s*\", IP_Image_Link) if word]\n",
        "        for link in simple_Url:\n",
        "            adapter_image.append(load_image(link))\n",
        "\n",
        "        # Creating the display\n",
        "        adapter_display = [element for element in adapter_image]\n",
        "        if len(adapter_image) % 3 == 0:\n",
        "            row = int(len(adapter_image)/3)\n",
        "        else:\n",
        "            row = int(len(adapter_image)/3) + 1\n",
        "            for i in range(3*row - len(adapter_image)):\n",
        "                adapter_display.append(load_image(\"https://huggingface.co/IDK-ab0ut/BFIDIW9W29NFJSKAOAOXDOKERJ29W/resolve/main/placeholder.png\"))\n",
        "        print(\"Image(s) for IP-Adapter:\")\n",
        "        display(make_image_grid([element.resize((1024, 1024)) for element in adapter_display], rows=row, cols=3))\n",
        "\n",
        "        # Loading the images to the IP-Adapter\n",
        "        image_embeds = [adapter_image]\n",
        "        pipeline.load_ip_adapter(\"h94/IP-Adapter\", subfolder=\"sdxl_models\", weight_name=IP_Adapter, low_cpu_mem_usage=True)\n",
        "        pipeline.set_ip_adapter_scale(IP_Adapter_Strength)\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    # Generate\n",
        "    if all(cn is None for cn in controlnets) and not active_inpaint and pipeline_type != \"img2img\": # For Text2Img\n",
        "        image_save = \"[Text-to-Image]\"\n",
        "        if IP_Adapter == \"None\":\n",
        "            image = pipeline(\n",
        "                prompt_embeds=conditioning[0:1],\n",
        "                pooled_prompt_embeds=pooled[0:1],\n",
        "                negative_prompt_embeds=conditioning[1:2],\n",
        "                negative_pooled_prompt_embeds=pooled[1:2],\n",
        "                num_inference_steps=Steps,\n",
        "                width=Width,\n",
        "                height=Height,\n",
        "                guidance_scale=Scale,\n",
        "                clip_skip=Clip_Skip,\n",
        "                generator=generator\n",
        "            ).images[0]\n",
        "        else:\n",
        "            image = pipeline(\n",
        "                prompt_embeds=conditioning[0:1],\n",
        "                pooled_prompt_embeds=pooled[0:1],\n",
        "                negative_prompt_embeds=conditioning[1:2],\n",
        "                negative_pooled_prompt_embeds=pooled[1:2],\n",
        "                num_inference_steps=Steps,\n",
        "                ip_adapter_image=image_embeds,\n",
        "                width=Width,\n",
        "                height=Height,\n",
        "                guidance_scale=Scale,\n",
        "                clip_skip=Clip_Skip,\n",
        "                generator=generator\n",
        "            ).images[0]\n",
        "            pipeline.unload_ip_adapter()\n",
        "    elif pipeline_type != \"img2img\" and active_inpaint and all(cn is None for cn in controlnets): # For Inpainting\n",
        "        image_save = \"[Inpainting]\"\n",
        "        if IP_Adapter == \"None\":\n",
        "            image = pipeline(\n",
        "                prompt_embeds=conditioning[0:1],\n",
        "                pooled_prompt_embeds=pooled[0:1],\n",
        "                negative_prompt_embeds=conditioning[1:2],\n",
        "                negative_pooled_prompt_embeds=pooled[1:2],\n",
        "                num_inference_steps=Steps,\n",
        "                width=Width,\n",
        "                height=Height,\n",
        "                guidance_scale=Scale,\n",
        "                clip_skip=Clip_Skip,\n",
        "                image=inpaint_image,\n",
        "                mask_image=mask_image,\n",
        "                generator=generator,\n",
        "                strength=Inpainting_Strength\n",
        "            ).images[0]\n",
        "        else:\n",
        "            image = pipeline(\n",
        "                prompt_embeds=conditioning[0:1],\n",
        "                pooled_prompt_embeds=pooled[0:1],\n",
        "                negative_prompt_embeds=conditioning[1:2],\n",
        "                negative_pooled_prompt_embeds=pooled[1:2],\n",
        "                num_inference_steps=Steps,\n",
        "                ip_adapter_image=image_embeds,\n",
        "                width=Width,\n",
        "                height=Height,\n",
        "                guidance_scale=Scale,\n",
        "                clip_skip=Clip_Skip,\n",
        "                generator=generator,\n",
        "                image=inpaint_image,\n",
        "                mask_image=mask_image,\n",
        "                strength=Inpainting_Strength\n",
        "            ).images[0]\n",
        "            pipeline.unload_ip_adapter()\n",
        "    elif pipeline_type != \"img2img\": # For ControlNet\n",
        "        image_save = \"[ControlNet]\"\n",
        "        if Inpainting:\n",
        "          if IP_Adapter == \"None\":\n",
        "            image = pipeline(\n",
        "                prompt_embeds=conditioning[0:1],\n",
        "                pooled_prompt_embeds=pooled[0:1],\n",
        "                negative_prompt_embeds=conditioning[1:2],\n",
        "                negative_pooled_prompt_embeds=pooled[1:2],\n",
        "                clip_skip=Clip_Skip,\n",
        "                num_inference_steps=Steps,\n",
        "                generator=generator,\n",
        "                width=Width,\n",
        "                height=Height,\n",
        "                image=[element for element in images if element is not None],\n",
        "                controlnet_conditioning_scale=[element for element in controlnets_scale if element],\n",
        "                guidance_scale=Scale\n",
        "            ).images[0]\n",
        "          else:\n",
        "            image = pipeline(\n",
        "                prompt_embeds=conditioning[0:1],\n",
        "                pooled_prompt_embeds=pooled[0:1],\n",
        "                negative_prompt_embeds=conditioning[1:2],\n",
        "                negative_pooled_prompt_embeds=pooled[1:2],\n",
        "                num_inference_steps=Steps,\n",
        "                ip_adapter_image=image_embeds,\n",
        "                width=Width,\n",
        "                height=Height,\n",
        "                guidance_scale=Scale,\n",
        "                clip_skip=Clip_Skip,\n",
        "                generator=generator,\n",
        "                image=[element for element in images if element is not None],\n",
        "                controlnet_conditioning_scale=[element for element in controlnets_scale if element]\n",
        "            ).images[0]\n",
        "    else: # For Img2img\n",
        "        image_save = \"[Image-to-Image]\"\n",
        "        if IP_Adapter == \"None\":\n",
        "            image = pipeline(\n",
        "                prompt_embeds=conditioning[0:1],\n",
        "                pooled_prompt_embeds=pooled[0:1],\n",
        "                negative_prompt_embeds=conditioning[1:2],\n",
        "                negative_pooled_prompt_embeds=pooled[1:2],\n",
        "                num_inference_steps=Steps,\n",
        "                width=Width,\n",
        "                height=Height,\n",
        "                image=ref_image,\n",
        "                strength=Denoising_Strength,\n",
        "                guidance_scale=Scale,\n",
        "                clip_skip=Clip_Skip,\n",
        "                generator=generator\n",
        "            ).images[0]\n",
        "        else:\n",
        "            image = pipeline(\n",
        "                prompt_embeds=conditioning[0:1],\n",
        "                pooled_prompt_embeds=pooled[0:1],\n",
        "                negative_prompt_embeds=conditioning[1:2],\n",
        "                negative_pooled_prompt_embeds=pooled[1:2],\n",
        "                num_inference_steps=Steps,\n",
        "                ip_adapter_image=image_embeds,\n",
        "                image=ref_image,\n",
        "                strength=Denoising_Strength,\n",
        "                width=Width,\n",
        "                height=Height,\n",
        "                guidance_scale=Scale,\n",
        "                clip_skip=Clip_Skip,\n",
        "                generator=generator\n",
        "            ).images[0]\n",
        "            pipeline.unload_ip_adapter()\n",
        "\n",
        "    # Saving the image\n",
        "    current_time = time.localtime()\n",
        "    formatted_time = time.strftime(\"[%H-%M-%S %B %d, %Y]\", current_time)\n",
        "    if Save_and_Connect_To_GDrive:\n",
        "        if image_save == \"[Text-to-Image]\":\n",
        "            image_save_path = \"/content/gdrive/MyDrive/Text2Img\"\n",
        "        elif image_save == \"[ControlNet]\":\n",
        "            image_save_path = \"/content/gdrive/MyDrive/ControlNet\"\n",
        "        elif image_save == \"[Inpainting]\":\n",
        "            image_save_path = \"/content/gdrive/MyDrive/Inpainting\"\n",
        "        else:\n",
        "            image_save_path = \"/content/gdrive/MyDrive/Img2Img\"\n",
        "    else:\n",
        "        if image_save == \"[Text-to-Image]\":\n",
        "            image_save_path = \"/content/Text2Img\"\n",
        "        elif image_save == \"[ControlNet]\":\n",
        "            image_save_path = \"/content/ControlNet\"\n",
        "        elif image_save == \"[Inpainting]\":\n",
        "            image_save_path = \"/content/Inpainting\"\n",
        "        else:\n",
        "            image_save_path = \"/content/Img2Img\"\n",
        "    if not os.path.exists(image_save_path):\n",
        "            os.makedirs(image_save_path)\n",
        "    split_prompt = re.split(\"\\s*,\\s*\", Prompt.replace(\"<\", \"\").replace(\">\", \"\").replace(\":\", \"_\").replace(\";\", \"_\"))\n",
        "    prompt_name = \" \".join(split_prompt)\n",
        "    generated_image_raw_filename = f\"{image_save} {formatted_time} {prompt_name}\"\n",
        "    generated_image_filename = generated_image_raw_filename[:251] if len(generated_image_raw_filename) > 255 else generated_image_raw_filename\n",
        "    generated_image_savefile = f\"{image_save_path}/{generated_image_filename}.png\"\n",
        "    image.save(generated_image_savefile)\n",
        "    widget()\n",
        "\n",
        "    # Saving parameters config 2nd phase\n",
        "    params = param_constructor()\n",
        "    save_param(f\"{base_path}/Saved Parameters/main_parameters.json\", params)\n",
        "\n",
        "    # Handling last generated image\n",
        "    last_generation_json = os.path.join(base_path, \"last_generation.json\")\n",
        "    save_last(last_generation_json, generated_image_savefile, image_save)\n",
        "\n",
        "    # Displaying the image, seed, and scheduler\n",
        "    display(image)\n",
        "    print(f\"Scheduler: {''.join(Scheduler_used)}\")\n",
        "    print(f\"Seed: {saved_number}\")\n",
        "    print(f\"Image is saved at {generated_image_savefile}.\")\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "# Lists to prevent ControlNet models from being loaded twice\n",
        "loaded_controlnet_model = [None] * 3\n",
        "controlnets = [None] * 3\n",
        "images = [None] * 3\n",
        "controlnets_scale = [None] * 3\n",
        "\n",
        "# Assigning the click event for submit_button_widget, loading lora urls from saved parameter, and displaying the ui\n",
        "submit_button_widget.on_click(submit)\n",
        "lora_reader_upon_starting()\n",
        "ti_reader_upon_starting()\n",
        "widget()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMmnx4mwtupU"
      },
      "source": [
        "\n",
        "###<font color=\"black\"> ¬ª <b><font color=\"purple\">Information </b>‚úèÔ∏èüìÑ</font> <font color=\"black\"> ¬´\n",
        "#####„Ö§\n",
        "<small>‚Ä¢ Text2Img image is saved in Text2Img folder. </small>\n",
        "\n",
        "<small>‚Ä¢ ControlNet-generated image is saved in ControlNet folder. (requires **Canny**, **Depth Map**, and/or **Open Pose** to be checked, as well as the direct link to the reference image) </small>\n",
        "\n",
        "<small>‚Ä¢ Inpainting-generated image is saved in Inpainting folder. (requires **Inpainting** to be checked, as well as inputting the image and the mask image)</small>\n",
        "\n",
        "<small> ‚Ä¢ You can't combine Inpainting and ControlNet.</small>\n",
        "\n",
        "<small>‚Ä¢ IP-Adapter doesn't change the image name.</small>\n",
        "\n",
        "<small>‚Ä¢ You can load LoRAs from your Google Drive by inputting their path. As of now, only LoRAs are supported. </small>\n",
        "\n",
        "<small>‚Ä¢ For ControlNet, leave the image link blank to use the last generated Text2Img image as the reference. Input \"inpaint\" to use the last generated Inpainting image. And lastly, input \"controlnet\" to use the last generated ControlNet image. (requires **Canny**, **Depth Map**, **Inpainting**, and/or **Open Pose** to be checked) </small>\n",
        "\n",
        "***\n",
        "\n",
        "###<font color=\"black\"> ¬ª <b><font color=\"cyan\">Guide </b>üö∂üèªüìã</font> <font color=\"black\"> ¬´\n",
        "#####„Ö§\n",
        "\n",
        "<small> **Prompt:** Basically, this one tells the AI what do you want to see in the image. Sometimes, you have to be strict with your words to align the image with your imagination.\n",
        "\n",
        "<small> **Model (**checkpoint**):** A saved state during an intense training. This is required to generate the image. The type of model you inputted affects the overall style.\n",
        "\n",
        "<small> **Model Format:** This is pretty self-explanatory. If you want to use .safetensors model, then set it to \"Safe Tensors.\"\n",
        "\n",
        "<small> **Steps:** It's simply how many iterations the AI will do in order to generate the image. More doesn't always better. You can look for references online.\n",
        "\n",
        "<small> **Scale (**Guidance Scale**):** This affects how closely related the image with the prompt. High value can be precise, but low value can add extra uniqueness.\n",
        "\n",
        "<small> **VAE:** Stands for Variational Autoencoder. It basically controls the color of your image.\n",
        "\n",
        "<small> **Clip Skip:** Lets the AI skip set amount of layers during generation.\n",
        "\n",
        "<small> **LoRA:** Stands for Low-Rank Adaptation. It holds weight to be \"fed\" to the AI. In simple terms, LoRA guides the AI to draw specific characters, style, poses, and so much more. You also need to specify the LoRA's scale, similar to **Scale**.\n",
        "\n",
        "<small> **ControlNet:** Basically a strict instruction based on the inputted image to generate image closely related to the reference.\n",
        "\n",
        "<small> **Inpainting:** Redrawing an image, but with certain parts of the image changed, just like editing with Photoshop, but AI does the job for you.\n",
        "\n",
        "<small> **IP-Adapter:** Similar to LoRA, but only follows the inputted image(s). This is stricter than LoRA and sometimes lacks generalization.\n",
        "\n",
        "<small> **Negative Prompt:** The reverse version of **Prompt**. Instead of telling the AI what do you want, this tells the AI about what do you want to be removed from the image."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "t8hug-0Okf8t"
      ],
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}