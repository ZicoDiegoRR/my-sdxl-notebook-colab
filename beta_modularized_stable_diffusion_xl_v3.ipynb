{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZicoDiegoRR/stable_diffusion_xl_colab_ui/blob/main/beta_modularized_stable_diffusion_xl_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8hug-0Okf8t"
      },
      "source": [
        "###<font color=\"black\"> ¬ª <b><font color=\"red\">Installing Dependencies </b>üíø</font> <font color=\"black\"> ¬´\n",
        "#####„Ö§Run this cell first before creating images!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GaGpmeILXSGl",
        "collapsed": true,
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown <b>Run this first to install essential libraries!</b><br>\n",
        "#@markdown <small><p>Required to use the generator.\n",
        "from IPython.display import clear_output\n",
        "\n",
        "print(\"‚öôÔ∏è | Downloading libraries...\")\n",
        "!git clone https://github.com/ZicoDiegoRR/stable_diffusion_xl_colab_ui.git StableDiffusionXLColabUI\n",
        "!pip install -r StableDiffusionXLColabUI/requirements.txt\n",
        "!pip install -r StableDiffusionXLColabUI/requirements_torch.txt\n",
        "\n",
        "!git clone https://github.com/xinntao/Real-ESRGAN.git RealESRGAN\n",
        "!pip install -r RealESRGAN/requirements.txt\n",
        "!pip install facexlib\n",
        "!pip install gfpgan\n",
        "!pip install basicsr-fixed\n",
        "%cd /content/RealESRGAN\n",
        "!python setup.py develop\n",
        "%cd /content\n",
        "\n",
        "clear_output()\n",
        "!export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True\n",
        "print(\"üìÅ | All essential libraries have been downloaded.\")\n",
        "print(\"üñå | You can start generating images now.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCBZ305GvH7w"
      },
      "source": [
        "###<font color=\"black\"> ¬ª<b><font color=\"orange\">Running Stable Diffusion</b> üîß</font> <font color=\"black\"> ¬´"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-sdjCI-xvy5",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#_______________________________________________________________________________________________________________________________________\n",
        "#@markdown <b>Run the cell to start!</b>\n",
        "\n",
        "#@markdown <small>Just run the cell and enjoy. (required to run the cell above first)</small>\n",
        "\n",
        "#@markdown <small>You can disable Google Drive by not permitting the notebook to access your Google Drive storage.</small>\n",
        "\n",
        "#@markdown <small>If the runtime got restarted, just run it again.</small>\n",
        "#_______________________________________________________________________________________________________________________________________\n",
        "\n",
        "from StableDiffusionXLColabUI.UI.ui_wrapper import UIWrapper\n",
        "from StableDiffusionXLColabUI.utils import preprocess\n",
        "\n",
        "# Preprocess the save file, ideas.txt, and GPT-2\n",
        "cfg, ideas_line, gpt2_pipe = preprocess.run()\n",
        "\n",
        "# Doing everything\n",
        "colab_ui = UIWrapper(cfg, ideas_line, gpt2_pipe)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMmnx4mwtupU"
      },
      "source": [
        "\n",
        "###<font color=\"black\"> ¬ª <b><font color=\"purple\">Information </b>‚úèÔ∏èüìÑ</font> <font color=\"black\"> ¬´\n",
        "#####„Ö§\n",
        "<small>‚Ä¢ Text2Img image is saved in Text2Img folder. </small>\n",
        "\n",
        "<small>‚Ä¢ Img2Img image is saved in Img2Img folder. (requires **Reference image** to be filled) </small>\n",
        "\n",
        "<small>‚Ä¢ ControlNet-generated image is saved in ControlNet folder. (requires **Enable Canny**, **Enable Depth Map**, and/or **Enable Open Pose** to be checked, as well as the direct link to the reference image) </small>\n",
        "\n",
        "<small>‚Ä¢ Inpainting-generated image is saved in Inpainting folder. (requires **Inpainting** to be checked, as well as inputting the image and the mask image)</small>\n",
        "\n",
        "<small> ‚Ä¢ You can't combine Inpainting and ControlNet.</small>\n",
        "\n",
        "<small>‚Ä¢ IP-Adapter doesn't change the image name.</small>\n",
        "\n",
        "<small>‚Ä¢ You can load LoRAs from your Google Drive by inputting their path. As of now, only LoRAs are supported. </small>\n",
        "\n",
        "<small>‚Ä¢ For ControlNet, leave the image link blank to use the last generated Text2Img image as the reference. Input \"inpaint\" to use the last generated Inpainting image. And lastly, input \"controlnet\" to use the last generated ControlNet image. (requires **Enable Canny**, **Enable Depth Map**, **Inpainting**, and/or **Enable Open Pose** to be checked) </small>\n",
        "\n",
        "***\n",
        "\n",
        "###<font color=\"black\"> ¬ª <b><font color=\"cyan\">Guide </b>üö∂üèªüìã</font> <font color=\"black\"> ¬´\n",
        "#####„Ö§\n",
        "\n",
        "<small> **Prompt:** Basically, this one tells the AI what do you want to see in the image. Sometimes, you have to be strict with your words to align the image with your imagination.\n",
        "\n",
        "<small> **Model (**checkpoint**):** A saved state during an intense training. This is required to generate the image. The type of model you inputted affects the overall style.\n",
        "\n",
        "<small> **Model Format:** This is pretty self-explanatory. If you want to use .safetensors model, then set it to \"Safe Tensors.\"\n",
        "\n",
        "<small> **Steps:** It's simply how many iterations the AI will do in order to generate the image. More doesn't always better. You can look for references online.\n",
        "\n",
        "<small> **Scale (**Guidance Scale**):** This affects how closely related the image with the prompt. High value can be precise, but low value can add extra uniqueness.\n",
        "\n",
        "<small> **VAE:** Stands for Variational Autoencoder. It basically controls the color of your image.\n",
        "\n",
        "<small> **Clip Skip:** Lets the AI skip set amount of layers during generation.\n",
        "\n",
        "<small> **LoRA:** Stands for Low-Rank Adaptation. It holds weight to be \"fed\" to the AI. In simple terms, LoRA guides the AI to draw specific characters, style, poses, and so much more. You also need to specify the LoRA's scale, similar to **Scale**.\n",
        "\n",
        "<small> **Image-to-Image:** This requires exactly one reference image. The AI will turn your image into something different or meaningful.\n",
        "\n",
        "<small> **Denoising Strength:** Exclusive for Image-to-image, this variable determines how extensive is the denoising process of the reference image. To put it simple, it determines how similar is the generated image compared to the reference. Low value means closely alike to the reference and high value means more changes to the image. Setting this to the maximum value, which is 1, will basically make the AI ignore the reference.\n",
        "\n",
        "<small> **ControlNet:** Basically a strict instruction based on the inputted image to generate image closely related to the reference.\n",
        "\n",
        "<small> **Inpainting:** Redrawing an image, but with certain parts of the image changed, just like editing with Photoshop, but AI does the job for you.\n",
        "\n",
        "<small> **IP-Adapter:** Similar to LoRA, but only follows the inputted image(s). This is stricter than LoRA and sometimes lacks generalization.\n",
        "\n",
        "<small> **Negative Prompt:** The reverse version of **Prompt**. Instead of telling the AI what do you want, this tells the AI about what do you want to be removed from the image."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "t8hug-0Okf8t"
      ],
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}